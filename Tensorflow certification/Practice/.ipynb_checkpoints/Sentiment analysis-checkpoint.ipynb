{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis ImDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb,info=tfds.load('imdb_reviews',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    version=1.0.0,\n",
       "    description='Large Movie Review Dataset.\n",
       "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'text': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    total_num_examples=100000,\n",
       "    splits={\n",
       "        'test': 25000,\n",
       "        'train': 25000,\n",
       "        'unsupervised': 50000,\n",
       "    },\n",
       "    supervised_keys=('text', 'label'),\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=imdb['train'],imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence=[]\n",
    "train_label=[]\n",
    "for lines in train_data:\n",
    "    train_sentence.append(str(lines[0].numpy()))\n",
    "    train_label.append(lines[1].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence=[]\n",
    "test_label=[]\n",
    "for lines in test_data:\n",
    "    test_sentence.append(str(lines[0].numpy()))\n",
    "    test_label.append(lines[1].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence=np.array(train_sentence)\n",
    "test_sentence=np.array(test_sentence)\n",
    "train_label=np.array(tain_label,dtype=np.int16)\n",
    "test_label=np.array(test_label,dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=10000\n",
    "embed_dim=16\n",
    "padding='post'\n",
    "oov_text='<OOV>'\n",
    "max_length=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(num_words=num_words,oov_token=oov_text)\n",
    "token.fit_on_texts(train_sentence)\n",
    "word_index=token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86539"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3Sequences\n",
    "train_seq=token.texts_to_sequences(train_sentence)\n",
    "test_seq=token.texts_to_sequences(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad_seq=pad_sequences(train_seq,maxlen=15,padding='pre')\n",
    "test_pad_seq=pad_sequences(test_seq,maxlen=15,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5,  746,    1,   17,   12, 2807,  115,   42,    6, 4518,  131,\n",
       "        424,    9, 6176,   47], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_seq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model creation\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 32)            320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                4240      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 327,057\n",
      "Trainable params: 327,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Embedding(input_dim=num_words,output_dim=32,input_length=15,))\n",
    "model.add(LSTM(20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.5473 - accuracy: 0.7056 - val_loss: 0.5048 - val_accuracy: 0.7454\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 20s 792us/sample - loss: 0.4301 - accuracy: 0.7943 - val_loss: 0.5111 - val_accuracy: 0.7442\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 20s 797us/sample - loss: 0.3657 - accuracy: 0.8244 - val_loss: 0.5803 - val_accuracy: 0.7410\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 20s 801us/sample - loss: 0.3059 - accuracy: 0.8547 - val_loss: 0.6246 - val_accuracy: 0.7332\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 19s 751us/sample - loss: 0.2480 - accuracy: 0.8848 - val_loss: 0.7518 - val_accuracy: 0.7214\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 20s 791us/sample - loss: 0.1976 - accuracy: 0.9102 - val_loss: 0.9239 - val_accuracy: 0.7176\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 20s 795us/sample - loss: 0.1543 - accuracy: 0.9311 - val_loss: 1.0759 - val_accuracy: 0.7165\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 20s 803us/sample - loss: 0.1155 - accuracy: 0.9527 - val_loss: 1.3411 - val_accuracy: 0.7146\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 20s 809us/sample - loss: 0.0910 - accuracy: 0.9650 - val_loss: 1.5894 - val_accuracy: 0.7136\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 19s 775us/sample - loss: 0.0685 - accuracy: 0.9741 - val_loss: 1.6694 - val_accuracy: 0.7111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21e0627c10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_seq,train_label,validation_data=(test_pad_seq,test_label),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE will save the weights and text to visualize in ts projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer=model.get_layer('embedding_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f21eadf7d90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer.get_weights()[0]\n",
    "arr_weights=embed_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embed_layer.get_weights()[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reversse the word index\n",
    "reverse_word_index=dict([(w,i) for i,w in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'performance'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Create files\n",
    "import io\n",
    "word_file=io.open('word_file.tsv','w',encoding='utf-8')\n",
    "vector_file=io.open('vector_file.tsv','w',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_words):\n",
    "    word_file.write(reverse_word_index[i+1])\n",
    "    vector_file.write('\\t'.join([str(x) for x in arr_weights[i]]) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
