{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will try to predict song which is Beat It!! by jackson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now load the song and create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They told him don't you ever come around here\n",
      "\n",
      "Don't want to see your face, you better disappear\n",
      "\n",
      "The fire's in their eyes and their words are really clear\n",
      "\n",
      "So beat it, just beat it\n",
      "\n",
      "You better run, you better do what you can\n",
      "\n",
      "Don't want to see no blood, don't be a macho man\n",
      "\n",
      "You want to be tough, better do what you can\n",
      "\n",
      "So beat it, but you want to be bad\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "They're out to get you, better leave while you can\n",
      "\n",
      "Don't want to be a boy, you want to be a man\n",
      "\n",
      "You want to stay alive, better do what you can\n",
      "\n",
      "So beat it, just beat it\n",
      "\n",
      "You have to show them that you're really not scared\n",
      "\n",
      "You're playin' with your life, this ain't no truth or dare\n",
      "\n",
      "They'll kick you, then they beat you,\n",
      "\n",
      "Then they'll tell you it's fair\n",
      "\n",
      "So beat it, but you want to be bad\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or who's right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Beat it, beat it, beat it\n"
     ]
    }
   ],
   "source": [
    "with open('Beat_it.txt','r',encoding='utf-8') as beatit:\n",
    "    for lines in beatit:\n",
    "        print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will create corpus of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "with open('Beat_it.txt','r',encoding='utf-8') as beatit:\n",
    "    for lines in beatit:\n",
    "        corpus.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer()\n",
    "token.fit_on_texts(corpus)\n",
    "word_index=token.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'it': 1,\n",
       " 'beat': 2,\n",
       " 'you': 3,\n",
       " 'to': 4,\n",
       " 'just': 5,\n",
       " 'be': 6,\n",
       " 'your': 7,\n",
       " 'no': 8,\n",
       " 'want': 9,\n",
       " 'and': 10,\n",
       " \"who's\": 11,\n",
       " 'or': 12,\n",
       " 'one': 13,\n",
       " 'wants': 14,\n",
       " 'defeated': 15,\n",
       " \"showin'\": 16,\n",
       " 'how': 17,\n",
       " 'funky': 18,\n",
       " 'strong': 19,\n",
       " 'is': 20,\n",
       " 'fight': 21,\n",
       " \"doesn't\": 22,\n",
       " 'matter': 23,\n",
       " 'wrong': 24,\n",
       " 'right': 25,\n",
       " 'better': 26,\n",
       " \"don't\": 27,\n",
       " 'so': 28,\n",
       " 'can': 29,\n",
       " 'do': 30,\n",
       " 'what': 31,\n",
       " 'a': 32,\n",
       " 'they': 33,\n",
       " 'see': 34,\n",
       " 'their': 35,\n",
       " 'really': 36,\n",
       " 'man': 37,\n",
       " 'but': 38,\n",
       " 'bad': 39,\n",
       " \"you're\": 40,\n",
       " \"they'll\": 41,\n",
       " 'then': 42,\n",
       " 'told': 43,\n",
       " 'him': 44,\n",
       " 'ever': 45,\n",
       " 'come': 46,\n",
       " 'around': 47,\n",
       " 'here': 48,\n",
       " 'face': 49,\n",
       " 'disappear': 50,\n",
       " 'the': 51,\n",
       " \"fire's\": 52,\n",
       " 'in': 53,\n",
       " 'eyes': 54,\n",
       " 'words': 55,\n",
       " 'are': 56,\n",
       " 'clear': 57,\n",
       " 'run': 58,\n",
       " 'blood': 59,\n",
       " 'macho': 60,\n",
       " 'tough': 61,\n",
       " \"they're\": 62,\n",
       " 'out': 63,\n",
       " 'get': 64,\n",
       " 'leave': 65,\n",
       " 'while': 66,\n",
       " 'boy': 67,\n",
       " 'stay': 68,\n",
       " 'alive': 69,\n",
       " 'have': 70,\n",
       " 'show': 71,\n",
       " 'them': 72,\n",
       " 'that': 73,\n",
       " 'not': 74,\n",
       " 'scared': 75,\n",
       " \"playin'\": 76,\n",
       " 'with': 77,\n",
       " 'life': 78,\n",
       " 'this': 79,\n",
       " \"ain't\": 80,\n",
       " 'truth': 81,\n",
       " 'dare': 82,\n",
       " 'kick': 83,\n",
       " 'tell': 84,\n",
       " \"it's\": 85,\n",
       " 'fair': 86}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_seq=token.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 43, 44, 27, 3, 45, 46, 47, 48],\n",
       " [27, 9, 4, 34, 7, 49, 3, 26, 50],\n",
       " [51, 52, 53, 35, 54, 10, 35, 55, 56, 36, 57],\n",
       " [28, 2, 1, 5, 2, 1],\n",
       " [3, 26, 58, 3, 26, 30, 31, 3, 29]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here comes the fun part\n",
    "##### from a single line we have to create multiple lines\n",
    "##### These lines starts with first word in the line and in the each step we will increment erach word\n",
    "##### and finally we will get set of sentences from a single corpus sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 52, 53, 35, 54, 10, 35, 55, 56, 36, 57]\n"
     ]
    }
   ],
   "source": [
    "text=corpus_seq[2]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will loop the text\n",
    "increment_text=[]\n",
    "\n",
    "for i in range(2,len(text)+1):\n",
    "    increment=text[:i]\n",
    "    increment_text.append(increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 52],\n",
       " [51, 52, 53],\n",
       " [51, 52, 53, 35],\n",
       " [51, 52, 53, 35, 54],\n",
       " [51, 52, 53, 35, 54, 10],\n",
       " [51, 52, 53, 35, 54, 10, 35],\n",
       " [51, 52, 53, 35, 54, 10, 35, 55],\n",
       " [51, 52, 53, 35, 54, 10, 35, 55, 56],\n",
       " [51, 52, 53, 35, 54, 10, 35, 55, 56, 36],\n",
       " [51, 52, 53, 35, 54, 10, 35, 55, 56, 36, 57]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is how it happens\n",
    "####  we will do that for all the corpus texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "increamental_text=[]\n",
    "for sentences in corpus_seq:\n",
    "    # WE will loop each sentence and create the incremental text\n",
    "    ## The range should be from two because while training and testing last word would go for output.\n",
    "    for i in range(2,len(sentences)):\n",
    "        increment=sentences[:i]\n",
    "        increamental_text.append(increment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(increamental_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 43],\n",
       " [33, 43, 44],\n",
       " [33, 43, 44, 27],\n",
       " [33, 43, 44, 27, 3],\n",
       " [33, 43, 44, 27, 3, 45],\n",
       " [33, 43, 44, 27, 3, 45, 46],\n",
       " [33, 43, 44, 27, 3, 45, 46, 47],\n",
       " [27, 9],\n",
       " [27, 9, 4],\n",
       " [27, 9, 4, 34],\n",
       " [27, 9, 4, 34, 7],\n",
       " [27, 9, 4, 34, 7, 49],\n",
       " [27, 9, 4, 34, 7, 49, 3],\n",
       " [27, 9, 4, 34, 7, 49, 3, 26],\n",
       " [51, 52],\n",
       " [51, 52, 53],\n",
       " [51, 52, 53, 35],\n",
       " [51, 52, 53, 35, 54],\n",
       " [51, 52, 53, 35, 54, 10],\n",
       " [51, 52, 53, 35, 54, 10, 35]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increamental_text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 43]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets take the maxlength to make every list equal in size.\n",
    "max_length=len(max(corpus_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_data_sequence=pad_sequences(increamental_text,maxlen=max_length,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_data_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 33, 43],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33, 43, 44],\n",
       "       [ 0,  0,  0,  0,  0,  0, 33, 43, 44, 27],\n",
       "       [ 0,  0,  0,  0,  0, 33, 43, 44, 27,  3],\n",
       "       [ 0,  0,  0,  0, 33, 43, 44, 27,  3, 45],\n",
       "       [ 0,  0,  0, 33, 43, 44, 27,  3, 45, 46],\n",
       "       [ 0,  0, 33, 43, 44, 27,  3, 45, 46, 47],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 27,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 27,  9,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0, 27,  9,  4, 34]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_data_sequence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets divide input and output\n",
    "#### The input will be all the sequence words except the last and the ouput will be the last sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pad_data_sequence[:,:-1]\n",
    "training_labels=pad_data_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 44, 27,  3, 45, 46, 47,  9,  4, 34], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traning_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "training_labels=to_categorical(training_labels,num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 86)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,LSTM,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 9, 64)             5568      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20)                6800      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 86)                1806      \n",
      "=================================================================\n",
      "Total params: 14,174\n",
      "Trainable params: 14,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "### Here max length is decremented with 1 beacuse one word has been removed from the corpus sequence\n",
    "model.add(Embedding(input_dim=vocab_size+1,output_dim=64,input_length=max_length-1))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(units=vocab_size,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 295 samples\n",
      "Epoch 1/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6949 - accuracy: 0.7966\n",
      "Epoch 2/500\n",
      "295/295 [==============================] - 0s 420us/sample - loss: 3.6940 - accuracy: 0.7966\n",
      "Epoch 3/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6928 - accuracy: 0.7966\n",
      "Epoch 4/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6917 - accuracy: 0.7966\n",
      "Epoch 5/500\n",
      "295/295 [==============================] - 0s 468us/sample - loss: 3.6909 - accuracy: 0.8000\n",
      "Epoch 6/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6897 - accuracy: 0.8034\n",
      "Epoch 7/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6888 - accuracy: 0.8034\n",
      "Epoch 8/500\n",
      "295/295 [==============================] - 0s 484us/sample - loss: 3.6880 - accuracy: 0.8034\n",
      "Epoch 9/500\n",
      "295/295 [==============================] - 0s 465us/sample - loss: 3.6873 - accuracy: 0.8034\n",
      "Epoch 10/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6864 - accuracy: 0.8034\n",
      "Epoch 11/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6857 - accuracy: 0.8034\n",
      "Epoch 12/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6850 - accuracy: 0.8034\n",
      "Epoch 13/500\n",
      "295/295 [==============================] - 0s 436us/sample - loss: 3.6844 - accuracy: 0.8034\n",
      "Epoch 14/500\n",
      "295/295 [==============================] - 0s 441us/sample - loss: 3.6839 - accuracy: 0.8034\n",
      "Epoch 15/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6834 - accuracy: 0.8034\n",
      "Epoch 16/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6827 - accuracy: 0.8034\n",
      "Epoch 17/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6823 - accuracy: 0.8034\n",
      "Epoch 18/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6819 - accuracy: 0.8034\n",
      "Epoch 19/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6814 - accuracy: 0.8034\n",
      "Epoch 20/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6810 - accuracy: 0.8034\n",
      "Epoch 21/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6807 - accuracy: 0.8034\n",
      "Epoch 22/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6805 - accuracy: 0.8034\n",
      "Epoch 23/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6802 - accuracy: 0.8034\n",
      "Epoch 24/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6800 - accuracy: 0.8034\n",
      "Epoch 25/500\n",
      "295/295 [==============================] - 0s 433us/sample - loss: 3.6798 - accuracy: 0.8034\n",
      "Epoch 26/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6795 - accuracy: 0.8034\n",
      "Epoch 27/500\n",
      "295/295 [==============================] - 0s 443us/sample - loss: 3.6793 - accuracy: 0.8034\n",
      "Epoch 28/500\n",
      "295/295 [==============================] - 0s 479us/sample - loss: 3.6791 - accuracy: 0.8034\n",
      "Epoch 29/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6789 - accuracy: 0.8034\n",
      "Epoch 30/500\n",
      "295/295 [==============================] - 0s 472us/sample - loss: 3.6787 - accuracy: 0.8034\n",
      "Epoch 31/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6786 - accuracy: 0.8034\n",
      "Epoch 32/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6784 - accuracy: 0.8034\n",
      "Epoch 33/500\n",
      "295/295 [==============================] - 0s 441us/sample - loss: 3.6783 - accuracy: 0.8034\n",
      "Epoch 34/500\n",
      "295/295 [==============================] - 0s 455us/sample - loss: 3.6782 - accuracy: 0.8034\n",
      "Epoch 35/500\n",
      "295/295 [==============================] - 0s 535us/sample - loss: 3.6780 - accuracy: 0.8034\n",
      "Epoch 36/500\n",
      "295/295 [==============================] - 0s 504us/sample - loss: 3.6779 - accuracy: 0.8034\n",
      "Epoch 37/500\n",
      "295/295 [==============================] - 0s 497us/sample - loss: 3.6777 - accuracy: 0.8034\n",
      "Epoch 38/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6776 - accuracy: 0.8034\n",
      "Epoch 39/500\n",
      "295/295 [==============================] - 0s 417us/sample - loss: 3.6775 - accuracy: 0.8034\n",
      "Epoch 40/500\n",
      "295/295 [==============================] - 0s 432us/sample - loss: 3.6774 - accuracy: 0.8034\n",
      "Epoch 41/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6772 - accuracy: 0.8034\n",
      "Epoch 42/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6771 - accuracy: 0.8034\n",
      "Epoch 43/500\n",
      "295/295 [==============================] - 0s 418us/sample - loss: 3.6770 - accuracy: 0.8034\n",
      "Epoch 44/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6769 - accuracy: 0.8034\n",
      "Epoch 45/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6768 - accuracy: 0.8034\n",
      "Epoch 46/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6766 - accuracy: 0.8034\n",
      "Epoch 47/500\n",
      "295/295 [==============================] - 0s 489us/sample - loss: 3.6765 - accuracy: 0.8034\n",
      "Epoch 48/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6763 - accuracy: 0.8034\n",
      "Epoch 49/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6762 - accuracy: 0.8034\n",
      "Epoch 50/500\n",
      "295/295 [==============================] - 0s 483us/sample - loss: 3.6761 - accuracy: 0.8034\n",
      "Epoch 51/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6759 - accuracy: 0.8034\n",
      "Epoch 52/500\n",
      "295/295 [==============================] - 0s 420us/sample - loss: 3.6757 - accuracy: 0.8034\n",
      "Epoch 53/500\n",
      "295/295 [==============================] - 0s 466us/sample - loss: 3.6755 - accuracy: 0.8034\n",
      "Epoch 54/500\n",
      "295/295 [==============================] - 0s 430us/sample - loss: 3.6752 - accuracy: 0.8034\n",
      "Epoch 55/500\n",
      "295/295 [==============================] - 0s 486us/sample - loss: 3.6749 - accuracy: 0.8034\n",
      "Epoch 56/500\n",
      "295/295 [==============================] - 0s 485us/sample - loss: 3.6743 - accuracy: 0.8034\n",
      "Epoch 57/500\n",
      "295/295 [==============================] - 0s 520us/sample - loss: 3.6736 - accuracy: 0.8034\n",
      "Epoch 58/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6725 - accuracy: 0.8034\n",
      "Epoch 59/500\n",
      "295/295 [==============================] - 0s 482us/sample - loss: 3.6703 - accuracy: 0.8203\n",
      "Epoch 60/500\n",
      "295/295 [==============================] - 0s 440us/sample - loss: 3.6680 - accuracy: 0.8203\n",
      "Epoch 61/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6648 - accuracy: 0.8305\n",
      "Epoch 62/500\n",
      "295/295 [==============================] - 0s 485us/sample - loss: 3.6600 - accuracy: 0.8305\n",
      "Epoch 63/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6578 - accuracy: 0.8305\n",
      "Epoch 64/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6559 - accuracy: 0.8305\n",
      "Epoch 65/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6551 - accuracy: 0.8305\n",
      "Epoch 66/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6536 - accuracy: 0.8305\n",
      "Epoch 67/500\n",
      "295/295 [==============================] - 0s 484us/sample - loss: 3.6531 - accuracy: 0.8305\n",
      "Epoch 68/500\n",
      "295/295 [==============================] - 0s 405us/sample - loss: 3.6525 - accuracy: 0.8305\n",
      "Epoch 69/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6520 - accuracy: 0.8305\n",
      "Epoch 70/500\n",
      "295/295 [==============================] - 0s 436us/sample - loss: 3.6517 - accuracy: 0.8305\n",
      "Epoch 71/500\n",
      "295/295 [==============================] - 0s 440us/sample - loss: 3.6514 - accuracy: 0.8305\n",
      "Epoch 72/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6511 - accuracy: 0.8305\n",
      "Epoch 73/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6507 - accuracy: 0.8305\n",
      "Epoch 74/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6505 - accuracy: 0.8305\n",
      "Epoch 75/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6502 - accuracy: 0.8305\n",
      "Epoch 76/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6500 - accuracy: 0.8305\n",
      "Epoch 77/500\n",
      "295/295 [==============================] - 0s 443us/sample - loss: 3.6497 - accuracy: 0.8305\n",
      "Epoch 78/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6495 - accuracy: 0.8305\n",
      "Epoch 79/500\n",
      "295/295 [==============================] - 0s 507us/sample - loss: 3.6493 - accuracy: 0.8305\n",
      "Epoch 80/500\n",
      "295/295 [==============================] - 0s 423us/sample - loss: 3.6490 - accuracy: 0.8305\n",
      "Epoch 81/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6488 - accuracy: 0.8305\n",
      "Epoch 82/500\n",
      "295/295 [==============================] - 0s 505us/sample - loss: 3.6485 - accuracy: 0.8305\n",
      "Epoch 83/500\n",
      "295/295 [==============================] - 0s 421us/sample - loss: 3.6483 - accuracy: 0.8339\n",
      "Epoch 84/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6480 - accuracy: 0.8339\n",
      "Epoch 85/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6477 - accuracy: 0.8339\n",
      "Epoch 86/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6474 - accuracy: 0.8339\n",
      "Epoch 87/500\n",
      "295/295 [==============================] - 0s 481us/sample - loss: 3.6471 - accuracy: 0.8339\n",
      "Epoch 88/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6468 - accuracy: 0.8373\n",
      "Epoch 89/500\n",
      "295/295 [==============================] - 0s 479us/sample - loss: 3.6464 - accuracy: 0.8373\n",
      "Epoch 90/500\n",
      "295/295 [==============================] - 0s 468us/sample - loss: 3.6461 - accuracy: 0.8373\n",
      "Epoch 91/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6457 - accuracy: 0.8373\n",
      "Epoch 92/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6453 - accuracy: 0.8373\n",
      "Epoch 93/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6450 - accuracy: 0.8373\n",
      "Epoch 94/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6446 - accuracy: 0.8373\n",
      "Epoch 95/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6442 - accuracy: 0.8373\n",
      "Epoch 96/500\n",
      "295/295 [==============================] - 0s 511us/sample - loss: 3.6439 - accuracy: 0.8373\n",
      "Epoch 97/500\n",
      "295/295 [==============================] - 0s 438us/sample - loss: 3.6435 - accuracy: 0.8373\n",
      "Epoch 98/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6432 - accuracy: 0.8373\n",
      "Epoch 99/500\n",
      "295/295 [==============================] - 0s 489us/sample - loss: 3.6427 - accuracy: 0.8373\n",
      "Epoch 100/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6425 - accuracy: 0.8373\n",
      "Epoch 101/500\n",
      "295/295 [==============================] - 0s 489us/sample - loss: 3.6421 - accuracy: 0.8373\n",
      "Epoch 102/500\n",
      "295/295 [==============================] - 0s 514us/sample - loss: 3.6418 - accuracy: 0.8373\n",
      "Epoch 103/500\n",
      "295/295 [==============================] - 0s 489us/sample - loss: 3.6415 - accuracy: 0.8373\n",
      "Epoch 104/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6413 - accuracy: 0.8407\n",
      "Epoch 105/500\n",
      "295/295 [==============================] - 0s 581us/sample - loss: 3.6410 - accuracy: 0.8407\n",
      "Epoch 106/500\n",
      "295/295 [==============================] - 0s 527us/sample - loss: 3.6408 - accuracy: 0.8407\n",
      "Epoch 107/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6404 - accuracy: 0.8441\n",
      "Epoch 108/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6402 - accuracy: 0.8441\n",
      "Epoch 109/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6399 - accuracy: 0.8441\n",
      "Epoch 110/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6396 - accuracy: 0.8441\n",
      "Epoch 111/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6394 - accuracy: 0.8441\n",
      "Epoch 112/500\n",
      "295/295 [==============================] - 0s 476us/sample - loss: 3.6391 - accuracy: 0.8441\n",
      "Epoch 113/500\n",
      "295/295 [==============================] - 0s 506us/sample - loss: 3.6389 - accuracy: 0.8441\n",
      "Epoch 114/500\n",
      "295/295 [==============================] - 0s 481us/sample - loss: 3.6386 - accuracy: 0.8441\n",
      "Epoch 115/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6384 - accuracy: 0.8441\n",
      "Epoch 116/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6381 - accuracy: 0.8441\n",
      "Epoch 117/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6379 - accuracy: 0.8441\n",
      "Epoch 118/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6377 - accuracy: 0.8441\n",
      "Epoch 119/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6376 - accuracy: 0.8441\n",
      "Epoch 120/500\n",
      "295/295 [==============================] - 0s 441us/sample - loss: 3.6373 - accuracy: 0.8441\n",
      "Epoch 121/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6371 - accuracy: 0.8441\n",
      "Epoch 122/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6370 - accuracy: 0.8441\n",
      "Epoch 123/500\n",
      "295/295 [==============================] - 0s 468us/sample - loss: 3.6368 - accuracy: 0.8441\n",
      "Epoch 124/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6366 - accuracy: 0.8441\n",
      "Epoch 125/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6365 - accuracy: 0.8441\n",
      "Epoch 126/500\n",
      "295/295 [==============================] - 0s 472us/sample - loss: 3.6364 - accuracy: 0.8441\n",
      "Epoch 127/500\n",
      "295/295 [==============================] - 0s 428us/sample - loss: 3.6361 - accuracy: 0.8441\n",
      "Epoch 128/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6360 - accuracy: 0.8441\n",
      "Epoch 129/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6359 - accuracy: 0.8441\n",
      "Epoch 130/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6358 - accuracy: 0.8441\n",
      "Epoch 131/500\n",
      "295/295 [==============================] - 0s 518us/sample - loss: 3.6357 - accuracy: 0.8441\n",
      "Epoch 132/500\n",
      "295/295 [==============================] - 0s 494us/sample - loss: 3.6355 - accuracy: 0.8441\n",
      "Epoch 133/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6355 - accuracy: 0.8441\n",
      "Epoch 134/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6353 - accuracy: 0.8441\n",
      "Epoch 135/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6353 - accuracy: 0.8441\n",
      "Epoch 136/500\n",
      "295/295 [==============================] - 0s 466us/sample - loss: 3.6352 - accuracy: 0.8441\n",
      "Epoch 137/500\n",
      "295/295 [==============================] - 0s 478us/sample - loss: 3.6351 - accuracy: 0.8441\n",
      "Epoch 138/500\n",
      "295/295 [==============================] - 0s 511us/sample - loss: 3.6350 - accuracy: 0.8441\n",
      "Epoch 139/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6349 - accuracy: 0.8441\n",
      "Epoch 140/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6348 - accuracy: 0.8441\n",
      "Epoch 141/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6347 - accuracy: 0.8441\n",
      "Epoch 142/500\n",
      "295/295 [==============================] - 0s 483us/sample - loss: 3.6346 - accuracy: 0.8441\n",
      "Epoch 143/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6345 - accuracy: 0.8441\n",
      "Epoch 144/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6344 - accuracy: 0.8441\n",
      "Epoch 145/500\n",
      "295/295 [==============================] - 0s 449us/sample - loss: 3.6344 - accuracy: 0.8441\n",
      "Epoch 146/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6343 - accuracy: 0.8441\n",
      "Epoch 147/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6342 - accuracy: 0.8441\n",
      "Epoch 148/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6342 - accuracy: 0.8441\n",
      "Epoch 149/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6341 - accuracy: 0.8441\n",
      "Epoch 150/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6340 - accuracy: 0.8441\n",
      "Epoch 151/500\n",
      "295/295 [==============================] - 0s 499us/sample - loss: 3.6339 - accuracy: 0.8441\n",
      "Epoch 152/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6339 - accuracy: 0.8441\n",
      "Epoch 153/500\n",
      "295/295 [==============================] - 0s 420us/sample - loss: 3.6338 - accuracy: 0.8441\n",
      "Epoch 154/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6338 - accuracy: 0.8441\n",
      "Epoch 155/500\n",
      "295/295 [==============================] - 0s 418us/sample - loss: 3.6337 - accuracy: 0.8441\n",
      "Epoch 156/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6337 - accuracy: 0.8441\n",
      "Epoch 157/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6336 - accuracy: 0.8441\n",
      "Epoch 158/500\n",
      "295/295 [==============================] - 0s 439us/sample - loss: 3.6335 - accuracy: 0.8441\n",
      "Epoch 159/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6335 - accuracy: 0.8441\n",
      "Epoch 160/500\n",
      "295/295 [==============================] - 0s 477us/sample - loss: 3.6334 - accuracy: 0.8441\n",
      "Epoch 161/500\n",
      "295/295 [==============================] - 0s 478us/sample - loss: 3.6334 - accuracy: 0.8441\n",
      "Epoch 162/500\n",
      "295/295 [==============================] - 0s 416us/sample - loss: 3.6333 - accuracy: 0.8441\n",
      "Epoch 163/500\n",
      "295/295 [==============================] - 0s 412us/sample - loss: 3.6333 - accuracy: 0.8441\n",
      "Epoch 164/500\n",
      "295/295 [==============================] - 0s 420us/sample - loss: 3.6332 - accuracy: 0.8441\n",
      "Epoch 165/500\n",
      "295/295 [==============================] - 0s 421us/sample - loss: 3.6332 - accuracy: 0.8441\n",
      "Epoch 166/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6331 - accuracy: 0.8441\n",
      "Epoch 167/500\n",
      "295/295 [==============================] - 0s 434us/sample - loss: 3.6331 - accuracy: 0.8441\n",
      "Epoch 168/500\n",
      "295/295 [==============================] - 0s 472us/sample - loss: 3.6330 - accuracy: 0.8441\n",
      "Epoch 169/500\n",
      "295/295 [==============================] - 0s 424us/sample - loss: 3.6330 - accuracy: 0.8441\n",
      "Epoch 170/500\n",
      "295/295 [==============================] - 0s 433us/sample - loss: 3.6329 - accuracy: 0.8441\n",
      "Epoch 171/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6329 - accuracy: 0.8441\n",
      "Epoch 172/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6328 - accuracy: 0.8441\n",
      "Epoch 173/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6328 - accuracy: 0.8441\n",
      "Epoch 174/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6327 - accuracy: 0.8441\n",
      "Epoch 175/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6326 - accuracy: 0.8441\n",
      "Epoch 176/500\n",
      "295/295 [==============================] - 0s 409us/sample - loss: 3.6325 - accuracy: 0.8441\n",
      "Epoch 177/500\n",
      "295/295 [==============================] - 0s 455us/sample - loss: 3.6325 - accuracy: 0.8441\n",
      "Epoch 178/500\n",
      "295/295 [==============================] - 0s 479us/sample - loss: 3.6324 - accuracy: 0.8441\n",
      "Epoch 179/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6323 - accuracy: 0.8441\n",
      "Epoch 180/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6322 - accuracy: 0.8441\n",
      "Epoch 181/500\n",
      "295/295 [==============================] - 0s 439us/sample - loss: 3.6321 - accuracy: 0.8441\n",
      "Epoch 182/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6320 - accuracy: 0.8475\n",
      "Epoch 183/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6319 - accuracy: 0.8475\n",
      "Epoch 184/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6318 - accuracy: 0.8475\n",
      "Epoch 185/500\n",
      "295/295 [==============================] - 0s 432us/sample - loss: 3.6316 - accuracy: 0.8475\n",
      "Epoch 186/500\n",
      "295/295 [==============================] - 0s 425us/sample - loss: 3.6314 - accuracy: 0.8475\n",
      "Epoch 187/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6313 - accuracy: 0.8475\n",
      "Epoch 188/500\n",
      "295/295 [==============================] - 0s 444us/sample - loss: 3.6311 - accuracy: 0.8475\n",
      "Epoch 189/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6308 - accuracy: 0.8475\n",
      "Epoch 190/500\n",
      "295/295 [==============================] - 0s 518us/sample - loss: 3.6307 - accuracy: 0.8508\n",
      "Epoch 191/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6303 - accuracy: 0.8508\n",
      "Epoch 192/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6302 - accuracy: 0.8508\n",
      "Epoch 193/500\n",
      "295/295 [==============================] - 0s 482us/sample - loss: 3.6297 - accuracy: 0.8508\n",
      "Epoch 194/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6295 - accuracy: 0.8508\n",
      "Epoch 195/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6292 - accuracy: 0.8508\n",
      "Epoch 196/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6289 - accuracy: 0.8508\n",
      "Epoch 197/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6287 - accuracy: 0.8508\n",
      "Epoch 198/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6285 - accuracy: 0.8508\n",
      "Epoch 199/500\n",
      "295/295 [==============================] - 0s 422us/sample - loss: 3.6282 - accuracy: 0.8508\n",
      "Epoch 200/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6280 - accuracy: 0.8508\n",
      "Epoch 201/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6279 - accuracy: 0.8508\n",
      "Epoch 202/500\n",
      "295/295 [==============================] - 0s 438us/sample - loss: 3.6277 - accuracy: 0.8508\n",
      "Epoch 203/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6275 - accuracy: 0.8508\n",
      "Epoch 204/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6274 - accuracy: 0.8508\n",
      "Epoch 205/500\n",
      "295/295 [==============================] - 0s 441us/sample - loss: 3.6272 - accuracy: 0.8508\n",
      "Epoch 206/500\n",
      "295/295 [==============================] - 0s 466us/sample - loss: 3.6271 - accuracy: 0.8508\n",
      "Epoch 207/500\n",
      "295/295 [==============================] - 0s 443us/sample - loss: 3.6270 - accuracy: 0.8508\n",
      "Epoch 208/500\n",
      "295/295 [==============================] - 0s 425us/sample - loss: 3.6268 - accuracy: 0.8508\n",
      "Epoch 209/500\n",
      "295/295 [==============================] - 0s 436us/sample - loss: 3.6267 - accuracy: 0.8508\n",
      "Epoch 210/500\n",
      "295/295 [==============================] - 0s 419us/sample - loss: 3.6265 - accuracy: 0.8508\n",
      "Epoch 211/500\n",
      "295/295 [==============================] - 0s 430us/sample - loss: 3.6264 - accuracy: 0.8508\n",
      "Epoch 212/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6262 - accuracy: 0.8508\n",
      "Epoch 213/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6261 - accuracy: 0.8508\n",
      "Epoch 214/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6258 - accuracy: 0.8508\n",
      "Epoch 215/500\n",
      "295/295 [==============================] - 0s 504us/sample - loss: 3.6256 - accuracy: 0.8508\n",
      "Epoch 216/500\n",
      "295/295 [==============================] - 0s 439us/sample - loss: 3.6253 - accuracy: 0.8508\n",
      "Epoch 217/500\n",
      "295/295 [==============================] - 0s 424us/sample - loss: 3.6249 - accuracy: 0.8542\n",
      "Epoch 218/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6246 - accuracy: 0.8542\n",
      "Epoch 219/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6243 - accuracy: 0.8542\n",
      "Epoch 220/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6239 - accuracy: 0.8542\n",
      "Epoch 221/500\n",
      "295/295 [==============================] - 0s 577us/sample - loss: 3.6237 - accuracy: 0.8542\n",
      "Epoch 222/500\n",
      "295/295 [==============================] - 0s 562us/sample - loss: 3.6235 - accuracy: 0.8542\n",
      "Epoch 223/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6234 - accuracy: 0.8542\n",
      "Epoch 224/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6232 - accuracy: 0.8542\n",
      "Epoch 225/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6231 - accuracy: 0.8542\n",
      "Epoch 226/500\n",
      "295/295 [==============================] - 0s 507us/sample - loss: 3.6230 - accuracy: 0.8542\n",
      "Epoch 227/500\n",
      "295/295 [==============================] - 0s 518us/sample - loss: 3.6229 - accuracy: 0.8542\n",
      "Epoch 228/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6228 - accuracy: 0.8542\n",
      "Epoch 229/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6228 - accuracy: 0.8542\n",
      "Epoch 230/500\n",
      "295/295 [==============================] - 0s 421us/sample - loss: 3.6227 - accuracy: 0.8542\n",
      "Epoch 231/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6226 - accuracy: 0.8542\n",
      "Epoch 232/500\n",
      "295/295 [==============================] - 0s 440us/sample - loss: 3.6226 - accuracy: 0.8542\n",
      "Epoch 233/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6225 - accuracy: 0.8542\n",
      "Epoch 234/500\n",
      "295/295 [==============================] - 0s 530us/sample - loss: 3.6225 - accuracy: 0.8542\n",
      "Epoch 235/500\n",
      "295/295 [==============================] - 0s 494us/sample - loss: 3.6224 - accuracy: 0.8542\n",
      "Epoch 236/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6224 - accuracy: 0.8542\n",
      "Epoch 237/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6223 - accuracy: 0.8542\n",
      "Epoch 238/500\n",
      "295/295 [==============================] - 0s 499us/sample - loss: 3.6223 - accuracy: 0.8542\n",
      "Epoch 239/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6223 - accuracy: 0.8542\n",
      "Epoch 240/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6222 - accuracy: 0.8542\n",
      "Epoch 241/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6222 - accuracy: 0.8542\n",
      "Epoch 242/500\n",
      "295/295 [==============================] - 0s 479us/sample - loss: 3.6221 - accuracy: 0.8542\n",
      "Epoch 243/500\n",
      "295/295 [==============================] - 0s 424us/sample - loss: 3.6221 - accuracy: 0.8542\n",
      "Epoch 244/500\n",
      "295/295 [==============================] - 0s 430us/sample - loss: 3.6221 - accuracy: 0.8542\n",
      "Epoch 245/500\n",
      "295/295 [==============================] - 0s 444us/sample - loss: 3.6220 - accuracy: 0.8542\n",
      "Epoch 246/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6220 - accuracy: 0.8542\n",
      "Epoch 247/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6219 - accuracy: 0.8542\n",
      "Epoch 248/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6219 - accuracy: 0.8542\n",
      "Epoch 249/500\n",
      "295/295 [==============================] - 0s 428us/sample - loss: 3.6218 - accuracy: 0.8542\n",
      "Epoch 250/500\n",
      "295/295 [==============================] - 0s 510us/sample - loss: 3.6218 - accuracy: 0.8542\n",
      "Epoch 251/500\n",
      "295/295 [==============================] - 0s 465us/sample - loss: 3.6217 - accuracy: 0.8542\n",
      "Epoch 252/500\n",
      "295/295 [==============================] - 0s 434us/sample - loss: 3.6216 - accuracy: 0.8542\n",
      "Epoch 253/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6215 - accuracy: 0.8542\n",
      "Epoch 254/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6214 - accuracy: 0.8542\n",
      "Epoch 255/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6213 - accuracy: 0.8542\n",
      "Epoch 256/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6211 - accuracy: 0.8542\n",
      "Epoch 257/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6209 - accuracy: 0.8576\n",
      "Epoch 258/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6207 - accuracy: 0.8576\n",
      "Epoch 259/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6204 - accuracy: 0.8576\n",
      "Epoch 260/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6202 - accuracy: 0.8576\n",
      "Epoch 261/500\n",
      "295/295 [==============================] - 0s 429us/sample - loss: 3.6197 - accuracy: 0.8576\n",
      "Epoch 262/500\n",
      "295/295 [==============================] - 0s 488us/sample - loss: 3.6195 - accuracy: 0.8576\n",
      "Epoch 263/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6192 - accuracy: 0.8576\n",
      "Epoch 264/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6189 - accuracy: 0.8610\n",
      "Epoch 265/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6187 - accuracy: 0.8610\n",
      "Epoch 266/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6184 - accuracy: 0.8610\n",
      "Epoch 267/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6182 - accuracy: 0.8610\n",
      "Epoch 268/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6179 - accuracy: 0.8610\n",
      "Epoch 269/500\n",
      "295/295 [==============================] - 0s 481us/sample - loss: 3.6177 - accuracy: 0.8610\n",
      "Epoch 270/500\n",
      "295/295 [==============================] - 0s 482us/sample - loss: 3.6175 - accuracy: 0.8610\n",
      "Epoch 271/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6172 - accuracy: 0.8610\n",
      "Epoch 272/500\n",
      "295/295 [==============================] - 0s 499us/sample - loss: 3.6171 - accuracy: 0.8610\n",
      "Epoch 273/500\n",
      "295/295 [==============================] - 0s 530us/sample - loss: 3.6169 - accuracy: 0.8610\n",
      "Epoch 274/500\n",
      "295/295 [==============================] - 0s 516us/sample - loss: 3.6167 - accuracy: 0.8610\n",
      "Epoch 275/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6165 - accuracy: 0.8610\n",
      "Epoch 276/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6164 - accuracy: 0.8610\n",
      "Epoch 277/500\n",
      "295/295 [==============================] - 0s 482us/sample - loss: 3.6163 - accuracy: 0.8610\n",
      "Epoch 278/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6161 - accuracy: 0.8610\n",
      "Epoch 279/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6159 - accuracy: 0.8610\n",
      "Epoch 280/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6158 - accuracy: 0.8610\n",
      "Epoch 281/500\n",
      "295/295 [==============================] - 0s 465us/sample - loss: 3.6157 - accuracy: 0.8610\n",
      "Epoch 282/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6156 - accuracy: 0.8610\n",
      "Epoch 283/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6156 - accuracy: 0.8610\n",
      "Epoch 284/500\n",
      "295/295 [==============================] - 0s 477us/sample - loss: 3.6155 - accuracy: 0.8610\n",
      "Epoch 285/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6155 - accuracy: 0.8610\n",
      "Epoch 286/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6155 - accuracy: 0.8610\n",
      "Epoch 287/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6154 - accuracy: 0.8610\n",
      "Epoch 288/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6154 - accuracy: 0.8610\n",
      "Epoch 289/500\n",
      "295/295 [==============================] - 0s 492us/sample - loss: 3.6153 - accuracy: 0.8610\n",
      "Epoch 290/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6153 - accuracy: 0.8610\n",
      "Epoch 291/500\n",
      "295/295 [==============================] - 0s 529us/sample - loss: 3.6152 - accuracy: 0.8610\n",
      "Epoch 292/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6152 - accuracy: 0.8610\n",
      "Epoch 293/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6152 - accuracy: 0.8610\n",
      "Epoch 294/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6151 - accuracy: 0.8610\n",
      "Epoch 295/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6151 - accuracy: 0.8610\n",
      "Epoch 296/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6151 - accuracy: 0.8610\n",
      "Epoch 297/500\n",
      "295/295 [==============================] - 0s 476us/sample - loss: 3.6151 - accuracy: 0.8610\n",
      "Epoch 298/500\n",
      "295/295 [==============================] - 0s 483us/sample - loss: 3.6150 - accuracy: 0.8610\n",
      "Epoch 299/500\n",
      "295/295 [==============================] - 0s 474us/sample - loss: 3.6150 - accuracy: 0.8610\n",
      "Epoch 300/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6150 - accuracy: 0.8610\n",
      "Epoch 301/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6149 - accuracy: 0.8610\n",
      "Epoch 302/500\n",
      "295/295 [==============================] - 0s 568us/sample - loss: 3.6149 - accuracy: 0.8610\n",
      "Epoch 303/500\n",
      "295/295 [==============================] - 0s 537us/sample - loss: 3.6149 - accuracy: 0.8610\n",
      "Epoch 304/500\n",
      "295/295 [==============================] - 0s 500us/sample - loss: 3.6149 - accuracy: 0.8610\n",
      "Epoch 305/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6149 - accuracy: 0.8610\n",
      "Epoch 306/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6148 - accuracy: 0.8610\n",
      "Epoch 307/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6148 - accuracy: 0.8610\n",
      "Epoch 308/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6148 - accuracy: 0.8610\n",
      "Epoch 309/500\n",
      "295/295 [==============================] - 0s 497us/sample - loss: 3.6148 - accuracy: 0.8610\n",
      "Epoch 310/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6147 - accuracy: 0.8610\n",
      "Epoch 311/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6147 - accuracy: 0.8610\n",
      "Epoch 312/500\n",
      "295/295 [==============================] - 0s 478us/sample - loss: 3.6147 - accuracy: 0.8610\n",
      "Epoch 313/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6147 - accuracy: 0.8610\n",
      "Epoch 314/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6147 - accuracy: 0.8610\n",
      "Epoch 315/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6146 - accuracy: 0.8610\n",
      "Epoch 316/500\n",
      "295/295 [==============================] - 0s 533us/sample - loss: 3.6146 - accuracy: 0.8610\n",
      "Epoch 317/500\n",
      "295/295 [==============================] - 0s 475us/sample - loss: 3.6146 - accuracy: 0.8610\n",
      "Epoch 318/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6146 - accuracy: 0.8610\n",
      "Epoch 319/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6146 - accuracy: 0.8610\n",
      "Epoch 320/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6145 - accuracy: 0.8610\n",
      "Epoch 321/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6145 - accuracy: 0.8610\n",
      "Epoch 322/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6145 - accuracy: 0.8610\n",
      "Epoch 323/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6144 - accuracy: 0.8610\n",
      "Epoch 324/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6144 - accuracy: 0.8610\n",
      "Epoch 325/500\n",
      "295/295 [==============================] - 0s 486us/sample - loss: 3.6144 - accuracy: 0.8610\n",
      "Epoch 326/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6144 - accuracy: 0.8610\n",
      "Epoch 327/500\n",
      "295/295 [==============================] - 0s 471us/sample - loss: 3.6143 - accuracy: 0.8610\n",
      "Epoch 328/500\n",
      "295/295 [==============================] - 0s 483us/sample - loss: 3.6143 - accuracy: 0.8610\n",
      "Epoch 329/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6143 - accuracy: 0.8610\n",
      "Epoch 330/500\n",
      "295/295 [==============================] - 0s 500us/sample - loss: 3.6142 - accuracy: 0.8610\n",
      "Epoch 331/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6142 - accuracy: 0.8610\n",
      "Epoch 332/500\n",
      "295/295 [==============================] - 0s 500us/sample - loss: 3.6141 - accuracy: 0.8610\n",
      "Epoch 333/500\n",
      "295/295 [==============================] - 0s 507us/sample - loss: 3.6141 - accuracy: 0.8610\n",
      "Epoch 334/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6140 - accuracy: 0.8610\n",
      "Epoch 335/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6139 - accuracy: 0.8610\n",
      "Epoch 336/500\n",
      "295/295 [==============================] - 0s 465us/sample - loss: 3.6138 - accuracy: 0.8610\n",
      "Epoch 337/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6137 - accuracy: 0.8644\n",
      "Epoch 338/500\n",
      "295/295 [==============================] - 0s 468us/sample - loss: 3.6135 - accuracy: 0.8644\n",
      "Epoch 339/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6134 - accuracy: 0.8644\n",
      "Epoch 340/500\n",
      "295/295 [==============================] - 0s 496us/sample - loss: 3.6133 - accuracy: 0.8644\n",
      "Epoch 341/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6130 - accuracy: 0.8644\n",
      "Epoch 342/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6129 - accuracy: 0.8644\n",
      "Epoch 343/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6127 - accuracy: 0.8644\n",
      "Epoch 344/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6125 - accuracy: 0.8644\n",
      "Epoch 345/500\n",
      "295/295 [==============================] - 0s 498us/sample - loss: 3.6123 - accuracy: 0.8644\n",
      "Epoch 346/500\n",
      "295/295 [==============================] - 0s 449us/sample - loss: 3.6121 - accuracy: 0.8644\n",
      "Epoch 347/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6120 - accuracy: 0.8644\n",
      "Epoch 348/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6118 - accuracy: 0.8644\n",
      "Epoch 349/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6117 - accuracy: 0.8644\n",
      "Epoch 350/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6116 - accuracy: 0.8644\n",
      "Epoch 351/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6115 - accuracy: 0.8644\n",
      "Epoch 352/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6114 - accuracy: 0.8644\n",
      "Epoch 353/500\n",
      "295/295 [==============================] - 0s 437us/sample - loss: 3.6113 - accuracy: 0.8644\n",
      "Epoch 354/500\n",
      "295/295 [==============================] - 0s 436us/sample - loss: 3.6113 - accuracy: 0.8644\n",
      "Epoch 355/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6112 - accuracy: 0.8644\n",
      "Epoch 356/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6111 - accuracy: 0.8644\n",
      "Epoch 357/500\n",
      "295/295 [==============================] - 0s 423us/sample - loss: 3.6111 - accuracy: 0.8644\n",
      "Epoch 358/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6111 - accuracy: 0.8644\n",
      "Epoch 359/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6110 - accuracy: 0.8644\n",
      "Epoch 360/500\n",
      "295/295 [==============================] - 0s 497us/sample - loss: 3.6110 - accuracy: 0.8644\n",
      "Epoch 361/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6110 - accuracy: 0.8644\n",
      "Epoch 362/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6109 - accuracy: 0.8644\n",
      "Epoch 363/500\n",
      "295/295 [==============================] - 0s 430us/sample - loss: 3.6109 - accuracy: 0.8644\n",
      "Epoch 364/500\n",
      "295/295 [==============================] - 0s 443us/sample - loss: 3.6108 - accuracy: 0.8644\n",
      "Epoch 365/500\n",
      "295/295 [==============================] - 0s 421us/sample - loss: 3.6108 - accuracy: 0.8644\n",
      "Epoch 366/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6108 - accuracy: 0.8644\n",
      "Epoch 367/500\n",
      "295/295 [==============================] - 0s 437us/sample - loss: 3.6107 - accuracy: 0.8644\n",
      "Epoch 368/500\n",
      "295/295 [==============================] - 0s 424us/sample - loss: 3.6106 - accuracy: 0.8644\n",
      "Epoch 369/500\n",
      "295/295 [==============================] - 0s 413us/sample - loss: 3.6106 - accuracy: 0.8644\n",
      "Epoch 370/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6106 - accuracy: 0.8644\n",
      "Epoch 371/500\n",
      "295/295 [==============================] - 0s 423us/sample - loss: 3.6105 - accuracy: 0.8644\n",
      "Epoch 372/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6103 - accuracy: 0.8644\n",
      "Epoch 373/500\n",
      "295/295 [==============================] - 0s 429us/sample - loss: 3.6102 - accuracy: 0.8644\n",
      "Epoch 374/500\n",
      "295/295 [==============================] - 0s 440us/sample - loss: 3.6099 - accuracy: 0.8644\n",
      "Epoch 375/500\n",
      "295/295 [==============================] - 0s 498us/sample - loss: 3.6098 - accuracy: 0.8678\n",
      "Epoch 376/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6095 - accuracy: 0.8678\n",
      "Epoch 377/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6093 - accuracy: 0.8678\n",
      "Epoch 378/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6091 - accuracy: 0.8678\n",
      "Epoch 379/500\n",
      "295/295 [==============================] - 0s 438us/sample - loss: 3.6091 - accuracy: 0.8678\n",
      "Epoch 380/500\n",
      "295/295 [==============================] - 0s 429us/sample - loss: 3.6087 - accuracy: 0.8678\n",
      "Epoch 381/500\n",
      "295/295 [==============================] - 0s 428us/sample - loss: 3.6086 - accuracy: 0.8678\n",
      "Epoch 382/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6085 - accuracy: 0.8678\n",
      "Epoch 383/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6084 - accuracy: 0.8678\n",
      "Epoch 384/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6082 - accuracy: 0.8678\n",
      "Epoch 385/500\n",
      "295/295 [==============================] - 0s 461us/sample - loss: 3.6082 - accuracy: 0.8678\n",
      "Epoch 386/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6080 - accuracy: 0.8678\n",
      "Epoch 387/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6081 - accuracy: 0.8678\n",
      "Epoch 388/500\n",
      "295/295 [==============================] - 0s 444us/sample - loss: 3.6079 - accuracy: 0.8678\n",
      "Epoch 389/500\n",
      "295/295 [==============================] - 0s 441us/sample - loss: 3.6080 - accuracy: 0.8678\n",
      "Epoch 390/500\n",
      "295/295 [==============================] - 0s 437us/sample - loss: 3.6077 - accuracy: 0.8678\n",
      "Epoch 391/500\n",
      "295/295 [==============================] - 0s 513us/sample - loss: 3.6076 - accuracy: 0.8678\n",
      "Epoch 392/500\n",
      "295/295 [==============================] - 0s 512us/sample - loss: 3.6075 - accuracy: 0.8678\n",
      "Epoch 393/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6074 - accuracy: 0.8678\n",
      "Epoch 394/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6072 - accuracy: 0.8678\n",
      "Epoch 395/500\n",
      "295/295 [==============================] - 0s 430us/sample - loss: 3.6069 - accuracy: 0.8678\n",
      "Epoch 396/500\n",
      "295/295 [==============================] - 0s 422us/sample - loss: 3.6066 - accuracy: 0.8678\n",
      "Epoch 397/500\n",
      "295/295 [==============================] - 0s 425us/sample - loss: 3.6063 - accuracy: 0.8712\n",
      "Epoch 398/500\n",
      "295/295 [==============================] - 0s 424us/sample - loss: 3.6058 - accuracy: 0.8746\n",
      "Epoch 399/500\n",
      "295/295 [==============================] - 0s 449us/sample - loss: 3.6054 - accuracy: 0.8746\n",
      "Epoch 400/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6050 - accuracy: 0.8746\n",
      "Epoch 401/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6043 - accuracy: 0.8746\n",
      "Epoch 402/500\n",
      "295/295 [==============================] - 0s 469us/sample - loss: 3.6041 - accuracy: 0.8746\n",
      "Epoch 403/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6045 - accuracy: 0.8712\n",
      "Epoch 404/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6034 - accuracy: 0.8746\n",
      "Epoch 405/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6031 - accuracy: 0.8746\n",
      "Epoch 406/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6026 - accuracy: 0.8746\n",
      "Epoch 407/500\n",
      "295/295 [==============================] - 0s 467us/sample - loss: 3.6025 - accuracy: 0.8746\n",
      "Epoch 408/500\n",
      "295/295 [==============================] - 0s 498us/sample - loss: 3.6024 - accuracy: 0.8746\n",
      "Epoch 409/500\n",
      "295/295 [==============================] - 0s 506us/sample - loss: 3.6022 - accuracy: 0.8746\n",
      "Epoch 410/500\n",
      "295/295 [==============================] - 0s 459us/sample - loss: 3.6021 - accuracy: 0.8746\n",
      "Epoch 411/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6020 - accuracy: 0.8746\n",
      "Epoch 412/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6019 - accuracy: 0.8746\n",
      "Epoch 413/500\n",
      "295/295 [==============================] - 0s 483us/sample - loss: 3.6018 - accuracy: 0.8746\n",
      "Epoch 414/500\n",
      "295/295 [==============================] - 0s 488us/sample - loss: 3.6017 - accuracy: 0.8746\n",
      "Epoch 415/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6017 - accuracy: 0.8746\n",
      "Epoch 416/500\n",
      "295/295 [==============================] - 0s 450us/sample - loss: 3.6016 - accuracy: 0.8746\n",
      "Epoch 417/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6016 - accuracy: 0.8746\n",
      "Epoch 418/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6015 - accuracy: 0.8746\n",
      "Epoch 419/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6015 - accuracy: 0.8746\n",
      "Epoch 420/500\n",
      "295/295 [==============================] - 0s 466us/sample - loss: 3.6014 - accuracy: 0.8746\n",
      "Epoch 421/500\n",
      "295/295 [==============================] - 0s 479us/sample - loss: 3.6014 - accuracy: 0.8746\n",
      "Epoch 422/500\n",
      "295/295 [==============================] - 0s 429us/sample - loss: 3.6013 - accuracy: 0.8746\n",
      "Epoch 423/500\n",
      "295/295 [==============================] - 0s 419us/sample - loss: 3.6013 - accuracy: 0.8746\n",
      "Epoch 424/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6013 - accuracy: 0.8746\n",
      "Epoch 425/500\n",
      "295/295 [==============================] - 0s 438us/sample - loss: 3.6012 - accuracy: 0.8746\n",
      "Epoch 426/500\n",
      "295/295 [==============================] - 0s 520us/sample - loss: 3.6012 - accuracy: 0.8746\n",
      "Epoch 427/500\n",
      "295/295 [==============================] - 0s 444us/sample - loss: 3.6012 - accuracy: 0.8746\n",
      "Epoch 428/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6011 - accuracy: 0.8746\n",
      "Epoch 429/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6011 - accuracy: 0.8746\n",
      "Epoch 430/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6011 - accuracy: 0.8746\n",
      "Epoch 431/500\n",
      "295/295 [==============================] - 0s 422us/sample - loss: 3.6011 - accuracy: 0.8746\n",
      "Epoch 432/500\n",
      "295/295 [==============================] - 0s 408us/sample - loss: 3.6010 - accuracy: 0.8746\n",
      "Epoch 433/500\n",
      "295/295 [==============================] - 0s 427us/sample - loss: 3.6010 - accuracy: 0.8746\n",
      "Epoch 434/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6010 - accuracy: 0.8746\n",
      "Epoch 435/500\n",
      "295/295 [==============================] - 0s 449us/sample - loss: 3.6010 - accuracy: 0.8746\n",
      "Epoch 436/500\n",
      "295/295 [==============================] - 0s 445us/sample - loss: 3.6010 - accuracy: 0.8746\n",
      "Epoch 437/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6009 - accuracy: 0.8746\n",
      "Epoch 438/500\n",
      "295/295 [==============================] - 0s 431us/sample - loss: 3.6009 - accuracy: 0.8746\n",
      "Epoch 439/500\n",
      "295/295 [==============================] - 0s 642us/sample - loss: 3.6009 - accuracy: 0.8746\n",
      "Epoch 440/500\n",
      "295/295 [==============================] - 0s 495us/sample - loss: 3.6009 - accuracy: 0.8746\n",
      "Epoch 441/500\n",
      "295/295 [==============================] - 0s 418us/sample - loss: 3.6009 - accuracy: 0.8746\n",
      "Epoch 442/500\n",
      "295/295 [==============================] - 0s 455us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 443/500\n",
      "295/295 [==============================] - 0s 420us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 444/500\n",
      "295/295 [==============================] - 0s 481us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 445/500\n",
      "295/295 [==============================] - 0s 551us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 446/500\n",
      "295/295 [==============================] - 0s 480us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 447/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6008 - accuracy: 0.8746\n",
      "Epoch 448/500\n",
      "295/295 [==============================] - 0s 525us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 449/500\n",
      "295/295 [==============================] - 0s 517us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 450/500\n",
      "295/295 [==============================] - 0s 491us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 451/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 452/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 453/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6007 - accuracy: 0.8746\n",
      "Epoch 454/500\n",
      "295/295 [==============================] - 0s 447us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 455/500\n",
      "295/295 [==============================] - 0s 444us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 456/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 457/500\n",
      "295/295 [==============================] - 0s 460us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 458/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 459/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 460/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 461/500\n",
      "295/295 [==============================] - 0s 474us/sample - loss: 3.6006 - accuracy: 0.8746\n",
      "Epoch 462/500\n",
      "295/295 [==============================] - 0s 515us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 463/500\n",
      "295/295 [==============================] - 0s 442us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 464/500\n",
      "295/295 [==============================] - 0s 453us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 465/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 466/500\n",
      "295/295 [==============================] - 0s 458us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 467/500\n",
      "295/295 [==============================] - 0s 456us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 468/500\n",
      "295/295 [==============================] - 0s 434us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 469/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 470/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6005 - accuracy: 0.8746\n",
      "Epoch 471/500\n",
      "295/295 [==============================] - 0s 528us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 472/500\n",
      "295/295 [==============================] - 0s 478us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 473/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 474/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 475/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 476/500\n",
      "295/295 [==============================] - 0s 435us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 477/500\n",
      "295/295 [==============================] - 0s 446us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 478/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 479/500\n",
      "295/295 [==============================] - 0s 473us/sample - loss: 3.6004 - accuracy: 0.8746\n",
      "Epoch 480/500\n",
      "295/295 [==============================] - 0s 515us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 481/500\n",
      "295/295 [==============================] - 0s 489us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 482/500\n",
      "295/295 [==============================] - 0s 452us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 483/500\n",
      "295/295 [==============================] - 0s 451us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 484/500\n",
      "295/295 [==============================] - 0s 470us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 485/500\n",
      "295/295 [==============================] - 0s 491us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 486/500\n",
      "295/295 [==============================] - 0s 476us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 487/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6003 - accuracy: 0.8746\n",
      "Epoch 488/500\n",
      "295/295 [==============================] - 0s 464us/sample - loss: 3.6002 - accuracy: 0.8746\n",
      "Epoch 489/500\n",
      "295/295 [==============================] - 0s 448us/sample - loss: 3.6002 - accuracy: 0.8746\n",
      "Epoch 490/500\n",
      "295/295 [==============================] - 0s 455us/sample - loss: 3.6002 - accuracy: 0.8746\n",
      "Epoch 491/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6002 - accuracy: 0.8746\n",
      "Epoch 492/500\n",
      "295/295 [==============================] - 0s 455us/sample - loss: 3.6001 - accuracy: 0.8746\n",
      "Epoch 493/500\n",
      "295/295 [==============================] - 0s 463us/sample - loss: 3.6001 - accuracy: 0.8746\n",
      "Epoch 494/500\n",
      "295/295 [==============================] - 0s 462us/sample - loss: 3.6001 - accuracy: 0.8746\n",
      "Epoch 495/500\n",
      "295/295 [==============================] - 0s 454us/sample - loss: 3.6001 - accuracy: 0.8746\n",
      "Epoch 496/500\n",
      "295/295 [==============================] - 0s 426us/sample - loss: 3.6000 - accuracy: 0.8746\n",
      "Epoch 497/500\n",
      "295/295 [==============================] - 0s 433us/sample - loss: 3.6000 - accuracy: 0.8746\n",
      "Epoch 498/500\n",
      "295/295 [==============================] - 0s 497us/sample - loss: 3.5999 - accuracy: 0.8746\n",
      "Epoch 499/500\n",
      "295/295 [==============================] - 0s 466us/sample - loss: 3.5998 - accuracy: 0.8746\n",
      "Epoch 500/500\n",
      "295/295 [==============================] - 0s 457us/sample - loss: 3.5998 - accuracy: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e742af110>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data,training_labels,epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets predict the model by asking the next word from the given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Don't want to see your\"\n",
    "text_list=[\"Don't want to see your\"]\n",
    "text_seq=token.texts_to_sequences(text_list)\n",
    "text_pad_seq=pad_sequences(text_seq,maxlen=max_length-1,padding='pre')\n",
    "text_pad_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(text_pad_seq).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index={w:i for i,w in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't want to see your face\n"
     ]
    }
   ],
   "source": [
    "predict_word=reverse_index[prediction]\n",
    "predict_text=text + ' ' +str(predict_word)\n",
    "print(predict_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets predict the next 50 words from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_words=50\n",
    "text=\"Don't want to see your\"\n",
    "text_list=[\"Don't want to see your\"]\n",
    "for i in range(50):\n",
    "    text_seq=token.texts_to_sequences(text_list)\n",
    "    text_pad_seq=pad_sequences(text_seq,maxlen=max_length-1,padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_index[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
