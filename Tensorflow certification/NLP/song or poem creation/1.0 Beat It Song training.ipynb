{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will try to predict song which is Beat It!! by jackson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now load the song and create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They told him don't you ever come around here\n",
      "\n",
      "Don't want to see your face, you better disappear\n",
      "\n",
      "The fire's in their eyes and their words are really clear\n",
      "\n",
      "So beat it, just beat it\n",
      "\n",
      "You better run, you better do what you can\n",
      "\n",
      "Don't want to see no blood, don't be a macho man\n",
      "\n",
      "You want to be tough, better do what you can\n",
      "\n",
      "So beat it, but you want to be bad\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "They're out to get you, better leave while you can\n",
      "\n",
      "Don't want to be a boy, you want to be a man\n",
      "\n",
      "You want to stay alive, better do what you can\n",
      "\n",
      "So beat it, just beat it\n",
      "\n",
      "You have to show them that you're really not scared\n",
      "\n",
      "You're playin' with your life, this ain't no truth or dare\n",
      "\n",
      "They'll kick you, then they beat you,\n",
      "\n",
      "Then they'll tell you it's fair\n",
      "\n",
      "So beat it, but you want to be bad\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or who's right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it, beat it, beat it\n",
      "\n",
      "No one wants to be defeated\n",
      "\n",
      "Showin' how funky and strong is your fight\n",
      "\n",
      "It doesn't matter who's wrong or right\n",
      "\n",
      "Just beat it, beat it\n",
      "\n",
      "Beat it, beat it, beat it\n"
     ]
    }
   ],
   "source": [
    "with open('Beat_it.txt','r',encoding='utf-8') as beatit:\n",
    "    for lines in beatit:\n",
    "        print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will create corpus of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "with open('irish-lyrics-eof.txt','r',encoding='utf-8') as beatit:\n",
    "    for lines in beatit:\n",
    "        corpus.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer()\n",
    "token.fit_on_texts(corpus)\n",
    "word_index=token.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2689\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'i': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'of': 6,\n",
       " 'my': 7,\n",
       " 'in': 8,\n",
       " 'me': 9,\n",
       " 'for': 10,\n",
       " 'you': 11,\n",
       " 'all': 12,\n",
       " 'was': 13,\n",
       " 'she': 14,\n",
       " 'that': 15,\n",
       " 'on': 16,\n",
       " 'with': 17,\n",
       " 'her': 18,\n",
       " 'but': 19,\n",
       " 'as': 20,\n",
       " 'when': 21,\n",
       " 'love': 22,\n",
       " 'is': 23,\n",
       " 'your': 24,\n",
       " 'it': 25,\n",
       " 'will': 26,\n",
       " 'from': 27,\n",
       " 'by': 28,\n",
       " 'they': 29,\n",
       " 'be': 30,\n",
       " 'are': 31,\n",
       " 'so': 32,\n",
       " 'he': 33,\n",
       " 'old': 34,\n",
       " 'no': 35,\n",
       " 'oh': 36,\n",
       " 'ill': 37,\n",
       " 'at': 38,\n",
       " 'one': 39,\n",
       " 'his': 40,\n",
       " 'there': 41,\n",
       " 'were': 42,\n",
       " 'heart': 43,\n",
       " 'down': 44,\n",
       " 'now': 45,\n",
       " 'we': 46,\n",
       " 'where': 47,\n",
       " 'young': 48,\n",
       " 'never': 49,\n",
       " 'go': 50,\n",
       " 'come': 51,\n",
       " 'then': 52,\n",
       " 'did': 53,\n",
       " 'not': 54,\n",
       " 'said': 55,\n",
       " 'away': 56,\n",
       " 'their': 57,\n",
       " 'sweet': 58,\n",
       " 'them': 59,\n",
       " 'green': 60,\n",
       " 'if': 61,\n",
       " 'take': 62,\n",
       " 'our': 63,\n",
       " 'like': 64,\n",
       " 'night': 65,\n",
       " 'day': 66,\n",
       " 'o': 67,\n",
       " 'out': 68,\n",
       " 'fair': 69,\n",
       " 'this': 70,\n",
       " 'town': 71,\n",
       " 'have': 72,\n",
       " 'can': 73,\n",
       " 'true': 74,\n",
       " 'its': 75,\n",
       " 'thou': 76,\n",
       " 'see': 77,\n",
       " 'dear': 78,\n",
       " 'more': 79,\n",
       " 'theres': 80,\n",
       " 'or': 81,\n",
       " 'had': 82,\n",
       " 'would': 83,\n",
       " 'over': 84,\n",
       " 'hear': 85,\n",
       " 'up': 86,\n",
       " 'ive': 87,\n",
       " 'through': 88,\n",
       " 'home': 89,\n",
       " 'again': 90,\n",
       " 'well': 91,\n",
       " 'oer': 92,\n",
       " 'land': 93,\n",
       " 'good': 94,\n",
       " 'im': 95,\n",
       " 'ye': 96,\n",
       " 'sea': 97,\n",
       " 'left': 98,\n",
       " 'still': 99,\n",
       " 'father': 100,\n",
       " 'long': 101,\n",
       " 'rose': 102,\n",
       " 'could': 103,\n",
       " 'morning': 104,\n",
       " 'wild': 105,\n",
       " 'who': 106,\n",
       " 'eyes': 107,\n",
       " 'came': 108,\n",
       " 'while': 109,\n",
       " 'too': 110,\n",
       " 'back': 111,\n",
       " 'little': 112,\n",
       " 'an': 113,\n",
       " 'took': 114,\n",
       " 'him': 115,\n",
       " 'bow': 116,\n",
       " 'first': 117,\n",
       " 'let': 118,\n",
       " 'man': 119,\n",
       " 'shall': 120,\n",
       " 'know': 121,\n",
       " 'get': 122,\n",
       " 'high': 123,\n",
       " 'gone': 124,\n",
       " 'say': 125,\n",
       " 'ever': 126,\n",
       " 'some': 127,\n",
       " 'mary': 128,\n",
       " 'hand': 129,\n",
       " 'till': 130,\n",
       " 'put': 131,\n",
       " 'own': 132,\n",
       " 'time': 133,\n",
       " 'heard': 134,\n",
       " 'dead': 135,\n",
       " 'may': 136,\n",
       " 'bright': 137,\n",
       " 'mountain': 138,\n",
       " 'early': 139,\n",
       " 'rosin': 140,\n",
       " 'gave': 141,\n",
       " 'thee': 142,\n",
       " 'only': 143,\n",
       " 'far': 144,\n",
       " 'maid': 145,\n",
       " 'must': 146,\n",
       " 'find': 147,\n",
       " 'girl': 148,\n",
       " 'sure': 149,\n",
       " 'round': 150,\n",
       " 'dublin': 151,\n",
       " 'once': 152,\n",
       " 'world': 153,\n",
       " 'delight': 154,\n",
       " 'last': 155,\n",
       " 'johnny': 156,\n",
       " 'seen': 157,\n",
       " 'has': 158,\n",
       " 'fine': 159,\n",
       " 'road': 160,\n",
       " 'mother': 161,\n",
       " 'tis': 162,\n",
       " 'what': 163,\n",
       " 'way': 164,\n",
       " 'moon': 165,\n",
       " 'soul': 166,\n",
       " 'neer': 167,\n",
       " 'id': 168,\n",
       " 'just': 169,\n",
       " 'thats': 170,\n",
       " 'days': 171,\n",
       " 'darling': 172,\n",
       " 'went': 173,\n",
       " 'white': 174,\n",
       " 'die': 175,\n",
       " 'than': 176,\n",
       " 'hair': 177,\n",
       " 'goes': 178,\n",
       " 'meet': 179,\n",
       " 'today': 180,\n",
       " 'do': 181,\n",
       " 'girls': 182,\n",
       " 'shes': 183,\n",
       " 'thyme': 184,\n",
       " 'thy': 185,\n",
       " 'sing': 186,\n",
       " 'pretty': 187,\n",
       " 'new': 188,\n",
       " 'poor': 189,\n",
       " 'into': 190,\n",
       " 'life': 191,\n",
       " 'irish': 192,\n",
       " 'give': 193,\n",
       " 'boy': 194,\n",
       " 'youre': 195,\n",
       " 'make': 196,\n",
       " 'passed': 197,\n",
       " 'lovely': 198,\n",
       " 'black': 199,\n",
       " 'youll': 200,\n",
       " 'died': 201,\n",
       " 'red': 202,\n",
       " 'smile': 203,\n",
       " 'keep': 204,\n",
       " 'loves': 205,\n",
       " 'free': 206,\n",
       " 'leave': 207,\n",
       " 'friends': 208,\n",
       " 'each': 209,\n",
       " 'saw': 210,\n",
       " 'behind': 211,\n",
       " 'song': 212,\n",
       " 'ra': 213,\n",
       " 'dont': 214,\n",
       " 'arms': 215,\n",
       " 'am': 216,\n",
       " 'sun': 217,\n",
       " 'saying': 218,\n",
       " 'made': 219,\n",
       " 'wish': 220,\n",
       " 'cold': 221,\n",
       " 'met': 222,\n",
       " 'before': 223,\n",
       " 'should': 224,\n",
       " 'rocky': 225,\n",
       " 'light': 226,\n",
       " 'wid': 227,\n",
       " 'boys': 228,\n",
       " 'best': 229,\n",
       " 'fields': 230,\n",
       " 'since': 231,\n",
       " 'ball': 232,\n",
       " 'water': 233,\n",
       " 'casey': 234,\n",
       " 'mind': 235,\n",
       " 'along': 236,\n",
       " 'loved': 237,\n",
       " 'place': 238,\n",
       " 'ireland': 239,\n",
       " 'next': 240,\n",
       " 'three': 241,\n",
       " 'many': 242,\n",
       " 'years': 243,\n",
       " 'door': 244,\n",
       " 'us': 245,\n",
       " 'drink': 246,\n",
       " 'got': 247,\n",
       " 'might': 248,\n",
       " 'live': 249,\n",
       " 'roses': 250,\n",
       " 'play': 251,\n",
       " 'soon': 252,\n",
       " 'ground': 253,\n",
       " 'times': 254,\n",
       " 'spent': 255,\n",
       " 'going': 256,\n",
       " 'tree': 257,\n",
       " 'barley': 258,\n",
       " 'grass': 259,\n",
       " 'kind': 260,\n",
       " 'twas': 261,\n",
       " 'bridge': 262,\n",
       " 'around': 263,\n",
       " 'blue': 264,\n",
       " 'tell': 265,\n",
       " 'row': 266,\n",
       " 'how': 267,\n",
       " 'money': 268,\n",
       " 'merry': 269,\n",
       " 'stepped': 270,\n",
       " 'corporal': 271,\n",
       " 'always': 272,\n",
       " 'though': 273,\n",
       " 'near': 274,\n",
       " 'taken': 275,\n",
       " 'ones': 276,\n",
       " 'daughter': 277,\n",
       " 'forever': 278,\n",
       " 'loo': 279,\n",
       " 'shining': 280,\n",
       " 'plenty': 281,\n",
       " 'hes': 282,\n",
       " 'ship': 283,\n",
       " 'banks': 284,\n",
       " 'think': 285,\n",
       " 'very': 286,\n",
       " 'stand': 287,\n",
       " 'heres': 288,\n",
       " 'snow': 289,\n",
       " 'mountains': 290,\n",
       " 'molly': 291,\n",
       " 'wheel': 292,\n",
       " 'street': 293,\n",
       " 'erin': 294,\n",
       " 'side': 295,\n",
       " 'feet': 296,\n",
       " 'star': 297,\n",
       " 'look': 298,\n",
       " 'brave': 299,\n",
       " 'woman': 300,\n",
       " 'sons': 301,\n",
       " 'two': 302,\n",
       " 'says': 303,\n",
       " 'asked': 304,\n",
       " 'lanigans': 305,\n",
       " 'singing': 306,\n",
       " 'men': 307,\n",
       " 'toome': 308,\n",
       " 'stole': 309,\n",
       " 'god': 310,\n",
       " 'hill': 311,\n",
       " 'lonely': 312,\n",
       " 'lover': 313,\n",
       " 'tears': 314,\n",
       " 'fathers': 315,\n",
       " 'low': 316,\n",
       " 'voice': 317,\n",
       " 'quite': 318,\n",
       " 'able': 319,\n",
       " 'nice': 320,\n",
       " 'laid': 321,\n",
       " 'comrades': 322,\n",
       " 'wind': 323,\n",
       " 'another': 324,\n",
       " 'sit': 325,\n",
       " 'face': 326,\n",
       " 'band': 327,\n",
       " 'call': 328,\n",
       " 'colleen': 329,\n",
       " 'until': 330,\n",
       " 'hills': 331,\n",
       " 'mine': 332,\n",
       " 'above': 333,\n",
       " 'upon': 334,\n",
       " 'eer': 335,\n",
       " 'youve': 336,\n",
       " 'fly': 337,\n",
       " 'been': 338,\n",
       " 'late': 339,\n",
       " 'alive': 340,\n",
       " 'ballyjamesduff': 341,\n",
       " 'looked': 342,\n",
       " 'great': 343,\n",
       " 'why': 344,\n",
       " 'every': 345,\n",
       " 'proud': 346,\n",
       " 'found': 347,\n",
       " 'bragh': 348,\n",
       " 'such': 349,\n",
       " 'birds': 350,\n",
       " 'wedding': 351,\n",
       " 'welcome': 352,\n",
       " 'dancing': 353,\n",
       " 'da': 354,\n",
       " 'fell': 355,\n",
       " 'thinking': 356,\n",
       " 'roddy': 357,\n",
       " 'mccorley': 358,\n",
       " 'smiling': 359,\n",
       " 'mallow': 360,\n",
       " 'blooming': 361,\n",
       " 'thought': 362,\n",
       " 'peace': 363,\n",
       " 'soft': 364,\n",
       " 'pure': 365,\n",
       " 'harp': 366,\n",
       " 'dream': 367,\n",
       " 'alas': 368,\n",
       " 'yet': 369,\n",
       " 'clear': 370,\n",
       " 'art': 371,\n",
       " 'off': 372,\n",
       " 'hope': 373,\n",
       " 'fought': 374,\n",
       " 'mothers': 375,\n",
       " 'shore': 376,\n",
       " 'ago': 377,\n",
       " 'fol': 378,\n",
       " 'de': 379,\n",
       " 'house': 380,\n",
       " 'married': 381,\n",
       " 'bound': 382,\n",
       " 'danced': 383,\n",
       " 'devil': 384,\n",
       " 'dawning': 385,\n",
       " 'makes': 386,\n",
       " 'same': 387,\n",
       " 'sat': 388,\n",
       " 'any': 389,\n",
       " 'glass': 390,\n",
       " 'gay': 391,\n",
       " 'relations': 392,\n",
       " 'evening': 393,\n",
       " 'watched': 394,\n",
       " 'right': 395,\n",
       " 'fellows': 396,\n",
       " 'whiskey': 397,\n",
       " 'bonnie': 398,\n",
       " 'grows': 399,\n",
       " 'women': 400,\n",
       " 'flowers': 401,\n",
       " 'beauty': 402,\n",
       " 'cannot': 403,\n",
       " 'handsome': 404,\n",
       " 'happy': 405,\n",
       " 'gold': 406,\n",
       " 'rover': 407,\n",
       " 'none': 408,\n",
       " 'doneen': 409,\n",
       " 'summers': 410,\n",
       " 'people': 411,\n",
       " 'set': 412,\n",
       " 'paddy': 413,\n",
       " 'morn': 414,\n",
       " 'most': 415,\n",
       " 'easy': 416,\n",
       " 'struck': 417,\n",
       " 'beautiful': 418,\n",
       " 'those': 419,\n",
       " 'golden': 420,\n",
       " 'run': 421,\n",
       " 'pipes': 422,\n",
       " 'glen': 423,\n",
       " 'dying': 424,\n",
       " 'here': 425,\n",
       " 'wall': 426,\n",
       " 'across': 427,\n",
       " 'fire': 428,\n",
       " 'eileen': 429,\n",
       " 'longer': 430,\n",
       " 'cheeks': 431,\n",
       " 'valley': 432,\n",
       " 'both': 433,\n",
       " 'dew': 434,\n",
       " 'care': 435,\n",
       " 'bride': 436,\n",
       " 'nothing': 437,\n",
       " 'wont': 438,\n",
       " 'theyre': 439,\n",
       " 'colonel': 440,\n",
       " 'maiden': 441,\n",
       " 'shed': 442,\n",
       " 'til': 443,\n",
       " 'brown': 444,\n",
       " 'breast': 445,\n",
       " 'corn': 446,\n",
       " 'sinking': 447,\n",
       " 'began': 448,\n",
       " 'name': 449,\n",
       " 'cruel': 450,\n",
       " 'sound': 451,\n",
       " 'spancil': 452,\n",
       " 'county': 453,\n",
       " 'lies': 454,\n",
       " 'color': 455,\n",
       " 'thing': 456,\n",
       " 'decay': 457,\n",
       " 'sleep': 458,\n",
       " 'hours': 459,\n",
       " 'loving': 460,\n",
       " 'weary': 461,\n",
       " 'ringing': 462,\n",
       " 'please': 463,\n",
       " 'forget': 464,\n",
       " 'lie': 465,\n",
       " 'ran': 466,\n",
       " 'tore': 467,\n",
       " 'country': 468,\n",
       " 'fear': 469,\n",
       " 'fortune': 470,\n",
       " 'kissed': 471,\n",
       " 'alone': 472,\n",
       " 'ould': 473,\n",
       " 'cry': 474,\n",
       " 'dreams': 475,\n",
       " 'used': 476,\n",
       " 'horse': 477,\n",
       " 'break': 478,\n",
       " 'bells': 479,\n",
       " 'didnt': 480,\n",
       " 'weeks': 481,\n",
       " 'without': 482,\n",
       " 'raw': 483,\n",
       " 'nor': 484,\n",
       " 'twenty': 485,\n",
       " 'tune': 486,\n",
       " 'hed': 487,\n",
       " 'roving': 488,\n",
       " 'leaves': 489,\n",
       " 'cant': 490,\n",
       " 'death': 491,\n",
       " 'ten': 492,\n",
       " 'prison': 493,\n",
       " 'judge': 494,\n",
       " 'against': 495,\n",
       " 'lads': 496,\n",
       " 'shell': 497,\n",
       " 'fill': 498,\n",
       " 'valleys': 499,\n",
       " 'other': 500,\n",
       " 'pale': 501,\n",
       " 'joy': 502,\n",
       " 'wide': 503,\n",
       " 'bring': 504,\n",
       " 'ah': 505,\n",
       " 'cliffs': 506,\n",
       " 'city': 507,\n",
       " 'end': 508,\n",
       " 'turn': 509,\n",
       " 'sky': 510,\n",
       " 'born': 511,\n",
       " 'knew': 512,\n",
       " 'smiled': 513,\n",
       " 'rosie': 514,\n",
       " 'comes': 515,\n",
       " 'sayin': 516,\n",
       " 'lord': 517,\n",
       " 'dungannon': 518,\n",
       " 'blood': 519,\n",
       " 'air': 520,\n",
       " 'danny': 521,\n",
       " 'calling': 522,\n",
       " 'sunshine': 523,\n",
       " 'spring': 524,\n",
       " 'bid': 525,\n",
       " 'grow': 526,\n",
       " 'truth': 527,\n",
       " 'tear': 528,\n",
       " 'rings': 529,\n",
       " 'guns': 530,\n",
       " 'bay': 531,\n",
       " 'oflynn': 532,\n",
       " 'och': 533,\n",
       " 'stick': 534,\n",
       " 'rest': 535,\n",
       " 'four': 536,\n",
       " 'jewel': 537,\n",
       " 'tried': 538,\n",
       " 'grief': 539,\n",
       " 'answer': 540,\n",
       " 'kathleen': 541,\n",
       " 'fond': 542,\n",
       " 'eye': 543,\n",
       " 'goin': 544,\n",
       " 'pistols': 545,\n",
       " 'musha': 546,\n",
       " 'whack': 547,\n",
       " 'creole': 548,\n",
       " 'together': 549,\n",
       " 'room': 550,\n",
       " 'fall': 551,\n",
       " 'swore': 552,\n",
       " 'being': 553,\n",
       " 'step': 554,\n",
       " 'lark': 555,\n",
       " 'cailín': 556,\n",
       " 'deas': 557,\n",
       " 'crúite': 558,\n",
       " 'na': 559,\n",
       " 'mbó': 560,\n",
       " 'sir': 561,\n",
       " 'isle': 562,\n",
       " 'waiting': 563,\n",
       " 'magic': 564,\n",
       " 'skibbereen': 565,\n",
       " 'loud': 566,\n",
       " 'raise': 567,\n",
       " 'bent': 568,\n",
       " 'aged': 569,\n",
       " 'summer': 570,\n",
       " 'jenny': 571,\n",
       " 'excise': 572,\n",
       " 'rigadoo': 573,\n",
       " 'auld': 574,\n",
       " 'hearts': 575,\n",
       " 'nay': 576,\n",
       " 'stool': 577,\n",
       " 'farrell': 578,\n",
       " 'garden': 579,\n",
       " 'precious': 580,\n",
       " 'child': 581,\n",
       " 'slumber': 582,\n",
       " 'sleeping': 583,\n",
       " 'watch': 584,\n",
       " 'gently': 585,\n",
       " 'minstrel': 586,\n",
       " 'praise': 587,\n",
       " 'bell': 588,\n",
       " 'shaken': 589,\n",
       " 'immortal': 590,\n",
       " 'pray': 591,\n",
       " 'stay': 592,\n",
       " 'spoke': 593,\n",
       " 'cross': 594,\n",
       " 'brothers': 595,\n",
       " 'much': 596,\n",
       " 'past': 597,\n",
       " 'killarney': 598,\n",
       " 'sang': 599,\n",
       " 'tones': 600,\n",
       " 'ral': 601,\n",
       " 'wander': 602,\n",
       " 'cot': 603,\n",
       " 'feel': 604,\n",
       " 'yore': 605,\n",
       " 'answered': 606,\n",
       " 'divil': 607,\n",
       " 'middle': 608,\n",
       " 'bit': 609,\n",
       " 'led': 610,\n",
       " 'soldiers': 611,\n",
       " 'lily': 612,\n",
       " 'bed': 613,\n",
       " 'lassie': 614,\n",
       " 'clothes': 615,\n",
       " 'return': 616,\n",
       " 'broken': 617,\n",
       " 'derry': 618,\n",
       " 'sighed': 619,\n",
       " 'english': 620,\n",
       " 'tomorrow': 621,\n",
       " 'souls': 622,\n",
       " 'van': 623,\n",
       " 'diemans': 624,\n",
       " 'law': 625,\n",
       " 'neither': 626,\n",
       " 'winds': 627,\n",
       " 'rather': 628,\n",
       " 'doesnt': 629,\n",
       " 'rosy': 630,\n",
       " 'neatest': 631,\n",
       " 'hands': 632,\n",
       " 'whereon': 633,\n",
       " 'stands': 634,\n",
       " 'write': 635,\n",
       " 'thousand': 636,\n",
       " 'fare': 637,\n",
       " 'youd': 638,\n",
       " 'velvet': 639,\n",
       " 'neat': 640,\n",
       " 'landed': 641,\n",
       " 'health': 642,\n",
       " 'kellswater': 643,\n",
       " 'quiet': 644,\n",
       " 'stars': 645,\n",
       " 'beside': 646,\n",
       " 'warm': 647,\n",
       " 'sunday': 648,\n",
       " 'grey': 649,\n",
       " 'ocean': 650,\n",
       " 'sad': 651,\n",
       " 'spend': 652,\n",
       " 'kilkenny': 653,\n",
       " 'silver': 654,\n",
       " 'view': 655,\n",
       " 'west': 656,\n",
       " 'plain': 657,\n",
       " 'barrow': 658,\n",
       " 'broad': 659,\n",
       " 'narrow': 660,\n",
       " 'crying': 661,\n",
       " 'wonder': 662,\n",
       " 'save': 663,\n",
       " 'stop': 664,\n",
       " 'tender': 665,\n",
       " 'told': 666,\n",
       " 'lip': 667,\n",
       " 'dance': 668,\n",
       " 'foot': 669,\n",
       " 'kilrain': 670,\n",
       " 'saint': 671,\n",
       " 'visit': 672,\n",
       " 'mossy': 673,\n",
       " 'wexford': 674,\n",
       " 'irishmen': 675,\n",
       " 'shadow': 676,\n",
       " 'tho': 677,\n",
       " 'salley': 678,\n",
       " 'gardens': 679,\n",
       " 'foolish': 680,\n",
       " 'youth': 681,\n",
       " 'fade': 682,\n",
       " 'war': 683,\n",
       " 'believe': 684,\n",
       " 'which': 685,\n",
       " 'change': 686,\n",
       " 'entwine': 687,\n",
       " 'turns': 688,\n",
       " 'turned': 689,\n",
       " 'crown': 690,\n",
       " 'played': 691,\n",
       " 'captain': 692,\n",
       " 'blow': 693,\n",
       " 'children': 694,\n",
       " 'slainte': 695,\n",
       " 'gentle': 696,\n",
       " 'heavens': 697,\n",
       " 'bloom': 698,\n",
       " 'grand': 699,\n",
       " 'bush': 700,\n",
       " 'nest': 701,\n",
       " 'rich': 702,\n",
       " 'parting': 703,\n",
       " 'better': 704,\n",
       " 'window': 705,\n",
       " 'haste': 706,\n",
       " 'fresh': 707,\n",
       " 'stream': 708,\n",
       " 'rays': 709,\n",
       " 'ma': 710,\n",
       " 'ring': 711,\n",
       " 'lad': 712,\n",
       " 'athy': 713,\n",
       " 'drop': 714,\n",
       " 'hardly': 715,\n",
       " 'done': 716,\n",
       " 'arm': 717,\n",
       " 'leg': 718,\n",
       " 'beg': 719,\n",
       " 'drew': 720,\n",
       " 'bold': 721,\n",
       " 'drawn': 722,\n",
       " 'jail': 723,\n",
       " 'writin': 724,\n",
       " 'farewell': 725,\n",
       " 'tired': 726,\n",
       " 'lake': 727,\n",
       " 'want': 728,\n",
       " 'ringlets': 729,\n",
       " 'myself': 730,\n",
       " 'songs': 731,\n",
       " 'reel': 732,\n",
       " 'steps': 733,\n",
       " 'hearty': 734,\n",
       " 'fainted': 735,\n",
       " 'called': 736,\n",
       " 'under': 737,\n",
       " 'toe': 738,\n",
       " 'mairi': 739,\n",
       " 'fairest': 740,\n",
       " 'darlin': 741,\n",
       " 'bird': 742,\n",
       " 'memory': 743,\n",
       " 'lips': 744,\n",
       " 'sweetly': 745,\n",
       " 'morrow': 746,\n",
       " 'consent': 747,\n",
       " 'else': 748,\n",
       " 'sold': 749,\n",
       " 'stout': 750,\n",
       " 'pair': 751,\n",
       " 'drinking': 752,\n",
       " 'meself': 753,\n",
       " 'fray': 754,\n",
       " 'pike': 755,\n",
       " 'coat': 756,\n",
       " 'beneath': 757,\n",
       " 'rent': 758,\n",
       " 'part': 759,\n",
       " 'half': 760,\n",
       " 'head': 761,\n",
       " 'friend': 762,\n",
       " 'standing': 763,\n",
       " 'floor': 764,\n",
       " 'bare': 765,\n",
       " 'wed': 766,\n",
       " 'son': 767,\n",
       " 'pride': 768,\n",
       " 'vision': 769,\n",
       " 'sword': 770,\n",
       " 'after': 771,\n",
       " 'won': 772,\n",
       " 'farmers': 773,\n",
       " 'flower': 774,\n",
       " 'nut': 775,\n",
       " 'surely': 776,\n",
       " 'stood': 777,\n",
       " 'wandered': 778,\n",
       " 'athenry': 779,\n",
       " 'rising': 780,\n",
       " 'beating': 781,\n",
       " 'form': 782,\n",
       " 'dhu': 783,\n",
       " 'buy': 784,\n",
       " 'laughter': 785,\n",
       " 'wear': 786,\n",
       " 'raking': 787,\n",
       " 'rakes': 788,\n",
       " 'claret': 789,\n",
       " 'shure': 790,\n",
       " 'tralee': 791,\n",
       " 'slower': 792,\n",
       " 'lower': 793,\n",
       " 'deep': 794,\n",
       " 'wearin': 795,\n",
       " 'duram': 796,\n",
       " 'takes': 797,\n",
       " 'beware': 798,\n",
       " 'steal': 799,\n",
       " 'brings': 800,\n",
       " 'things': 801,\n",
       " 'joys': 802,\n",
       " 'bunch': 803,\n",
       " 'sailor': 804,\n",
       " 'chanced': 805,\n",
       " 'pass': 806,\n",
       " 'angels': 807,\n",
       " 'send': 808,\n",
       " 'drowsy': 809,\n",
       " 'keeping': 810,\n",
       " 'spirit': 811,\n",
       " 'stealing': 812,\n",
       " 'feeling': 813,\n",
       " 'roam': 814,\n",
       " 'presence': 815,\n",
       " 'heavenward': 816,\n",
       " 'dust': 817,\n",
       " 'dim': 818,\n",
       " 'journey': 819,\n",
       " 'waves': 820,\n",
       " 'frightened': 821,\n",
       " 'leaving': 822,\n",
       " 'struggle': 823,\n",
       " 'parents': 824,\n",
       " 'courage': 825,\n",
       " 'weeping': 826,\n",
       " 'pain': 827,\n",
       " 'mist': 828,\n",
       " 'felt': 829,\n",
       " 'roared': 830,\n",
       " 'making': 831,\n",
       " 'fever': 832,\n",
       " 'moment': 833,\n",
       " 'distance': 834,\n",
       " 'wailing': 835,\n",
       " 'oft': 836,\n",
       " 'held': 837,\n",
       " 'fast': 838,\n",
       " 'cabin': 839,\n",
       " 'honey': 840,\n",
       " 'diddle': 841,\n",
       " 'clearly': 842,\n",
       " 'open': 843,\n",
       " 'opened': 844,\n",
       " 'table': 845,\n",
       " 'wine': 846,\n",
       " 'lay': 847,\n",
       " 'shells': 848,\n",
       " 'sailed': 849,\n",
       " 'drown': 850,\n",
       " 'fetters': 851,\n",
       " 'chains': 852,\n",
       " 'wives': 853,\n",
       " 'sorrow': 854,\n",
       " 'thoughts': 855,\n",
       " 'cursed': 856,\n",
       " 'hell': 857,\n",
       " 'five': 858,\n",
       " 'buried': 859,\n",
       " 'lost': 860,\n",
       " 'endless': 861,\n",
       " 'slavery': 862,\n",
       " 'gun': 863,\n",
       " 'rain': 864,\n",
       " 'cares': 865,\n",
       " 'ghosts': 866,\n",
       " 'runaway': 867,\n",
       " 'twill': 868,\n",
       " 'month': 869,\n",
       " 'meadows': 870,\n",
       " 'prettiest': 871,\n",
       " 'winters': 872,\n",
       " 'satisfied': 873,\n",
       " 'few': 874,\n",
       " 'short': 875,\n",
       " 'lines': 876,\n",
       " 'shone': 877,\n",
       " 'shoulder': 878,\n",
       " 'belfast': 879,\n",
       " 'trade': 880,\n",
       " 'bad': 881,\n",
       " 'caused': 882,\n",
       " 'stray': 883,\n",
       " 'meaning': 884,\n",
       " 'damsel': 885,\n",
       " 'appear': 886,\n",
       " 'seven': 887,\n",
       " 'sentence': 888,\n",
       " 'jolly': 889,\n",
       " 'whenever': 890,\n",
       " 'wee': 891,\n",
       " 'wife': 892,\n",
       " 'lives': 893,\n",
       " 'martha': 894,\n",
       " 'courted': 895,\n",
       " 'bridgit': 896,\n",
       " 'omalley': 897,\n",
       " 'desolation': 898,\n",
       " 'thorn': 899,\n",
       " 'gaze': 900,\n",
       " 'stone': 901,\n",
       " 'approaching': 902,\n",
       " 'sets': 903,\n",
       " 'carrigfergus': 904,\n",
       " 'nights': 905,\n",
       " 'swim': 906,\n",
       " 'wings': 907,\n",
       " 'sober': 908,\n",
       " 'travel': 909,\n",
       " 'native': 910,\n",
       " 'places': 911,\n",
       " 'slopes': 912,\n",
       " 'hares': 913,\n",
       " 'lofty': 914,\n",
       " 'malone': 915,\n",
       " 'wheeled': 916,\n",
       " 'streets': 917,\n",
       " 'enough': 918,\n",
       " 'reilly': 919,\n",
       " 'tough': 920,\n",
       " 'whispers': 921,\n",
       " 'phil': 922,\n",
       " 'threw': 923,\n",
       " 'straight': 924,\n",
       " 'belles': 925,\n",
       " 'moor': 926,\n",
       " 'brand': 927,\n",
       " 'shapes': 928,\n",
       " 'work': 929,\n",
       " 'vow': 930,\n",
       " 'blarney': 931,\n",
       " 'paid': 932,\n",
       " 'bower': 933,\n",
       " 'remain': 934,\n",
       " 'charming': 935,\n",
       " 'storied': 936,\n",
       " 'chieftains': 937,\n",
       " 'slaughter': 938,\n",
       " 'bann': 939,\n",
       " 'boyne': 940,\n",
       " 'liffey': 941,\n",
       " 'gallant': 942,\n",
       " 'awake': 943,\n",
       " 'greet': 944,\n",
       " 'meadow': 945,\n",
       " 'sweeter': 946,\n",
       " 'dirty': 947,\n",
       " 'cats': 948,\n",
       " 'crossed': 949,\n",
       " 'field': 950,\n",
       " 'river': 951,\n",
       " 'full': 952,\n",
       " 'aroon': 953,\n",
       " 'sends': 954,\n",
       " 'woe': 955,\n",
       " 'chain': 956,\n",
       " 'main': 957,\n",
       " 'charms': 958,\n",
       " 'fondly': 959,\n",
       " 'fleet': 960,\n",
       " 'fairy': 961,\n",
       " 'thine': 962,\n",
       " 'known': 963,\n",
       " 'truly': 964,\n",
       " 'close': 965,\n",
       " 'story': 966,\n",
       " 'flag': 967,\n",
       " 'sweetest': 968,\n",
       " 'honor': 969,\n",
       " 'playing': 970,\n",
       " 'mauser': 971,\n",
       " 'music': 972,\n",
       " 'tom': 973,\n",
       " 'hurrah': 974,\n",
       " 'big': 975,\n",
       " 'lead': 976,\n",
       " 'south': 977,\n",
       " 'generation': 978,\n",
       " 'freedom': 979,\n",
       " 'agin': 980,\n",
       " 'creature': 981,\n",
       " 'dad': 982,\n",
       " 'venture': 983,\n",
       " 'word': 984,\n",
       " 'wonderful': 985,\n",
       " 'crazy': 986,\n",
       " 'lazy': 987,\n",
       " 'grave': 988,\n",
       " 'jest': 989,\n",
       " 'remark': 990,\n",
       " 'strangers': 991,\n",
       " 'strong': 992,\n",
       " 'shook': 993,\n",
       " 'walk': 994,\n",
       " 'north': 995,\n",
       " 'ours': 996,\n",
       " 'cease': 997,\n",
       " 'strife': 998,\n",
       " 'whats': 999,\n",
       " 'lilacs': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_seq=token.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 12, 96, 1217, 48, 2, 69],\n",
       " [2, 11, 15, 31, 361, 8, 24, 1218],\n",
       " [272, 798, 2, 204, 24, 579, 69],\n",
       " [118, 35, 119, 799, 56, 24, 184],\n",
       " [10, 184, 25, 23, 5, 580, 456]]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here comes the fun part\n",
    "##### from a single line we have to create multiple lines\n",
    "##### These lines starts with first word in the line and in the each step we will increment erach word\n",
    "##### and finally we will get set of sentences from a single corpus sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[272, 798, 2, 204, 24, 579, 69]\n"
     ]
    }
   ],
   "source": [
    "text=corpus_seq[2]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will loop the text\n",
    "increment_text=[]\n",
    "\n",
    "for i in range(2,len(text)+1):\n",
    "    increment=text[:i]\n",
    "    increment_text.append(increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[272, 798],\n",
       " [272, 798, 2],\n",
       " [272, 798, 2, 204],\n",
       " [272, 798, 2, 204, 24],\n",
       " [272, 798, 2, 204, 24, 579],\n",
       " [272, 798, 2, 204, 24, 579, 69]]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is how it happens\n",
    "####  we will do that for all the corpus texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "increamental_text=[]\n",
    "for sentences in corpus_seq:\n",
    "    # WE will loop each sentence and create the incremental text\n",
    "    ## The range should be from two because while training and testing last word would go for output.\n",
    "    for i in range(2,len(sentences)):\n",
    "        increment=sentences[:i]\n",
    "        increamental_text.append(increment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10346"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(increamental_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 12],\n",
       " [51, 12, 96],\n",
       " [51, 12, 96, 1217],\n",
       " [51, 12, 96, 1217, 48],\n",
       " [51, 12, 96, 1217, 48, 2],\n",
       " [2, 11],\n",
       " [2, 11, 15],\n",
       " [2, 11, 15, 31],\n",
       " [2, 11, 15, 31, 361],\n",
       " [2, 11, 15, 31, 361, 8],\n",
       " [2, 11, 15, 31, 361, 8, 24],\n",
       " [272, 798],\n",
       " [272, 798, 2],\n",
       " [272, 798, 2, 204],\n",
       " [272, 798, 2, 204, 24],\n",
       " [272, 798, 2, 204, 24, 579],\n",
       " [118, 35],\n",
       " [118, 35, 119],\n",
       " [118, 35, 119, 799],\n",
       " [118, 35, 119, 799, 56]]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increamental_text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To get the length of max number of items in the list \n",
    "max_length=0\n",
    "for i in corpus_seq:\n",
    "    if len(i) > max_length:\n",
    "        max_length=len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_data_sequence=pad_sequences(increamental_text,maxlen=max_length,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10346, 16)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_data_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,   51,   12],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,   51,   12,   96],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   51,   12,   96, 1217],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          51,   12,   96, 1217,   48],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   51,\n",
       "          12,   96, 1217,   48,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,   11],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,   11,   15],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    2,   11,   15,   31],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           2,   11,   15,   31,  361],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    2,\n",
       "          11,   15,   31,  361,    8]], dtype=int32)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_data_sequence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets divide input and output\n",
    "#### The input will be all the sequence words except the last and the ouput will be the last sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pad_data_sequence[:,:-1]\n",
    "training_labels=pad_data_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 44, 27,  3, 45, 46, 47,  9,  4, 34], dtype=int32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traning_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10346, 15)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "training_labels=to_categorical(training_labels,num_classes=vocab_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10346, 2690)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,LSTM,Embedding,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 15, 100)           269000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2690)              406190    \n",
      "=================================================================\n",
      "Total params: 825,790\n",
      "Trainable params: 825,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "### Here max length is decremented with 1 beacuse one word has been removed from the corpus sequence\n",
    "model.add(Embedding(input_dim=vocab_size+1,output_dim=100,input_length=max_length-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(units=vocab_size+1,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10346 samples\n",
      "Epoch 1/50\n",
      "10346/10346 [==============================] - 14s 1ms/sample - loss: 7.8382 - accuracy: 0.0749\n",
      "Epoch 2/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 3/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 4/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 5/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 6/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 7/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 8/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 9/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 10/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 11/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 12/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 13/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 14/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 15/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 16/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 17/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 18/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 19/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 20/50\n",
      "10346/10346 [==============================] - 12s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 21/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 22/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 23/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 24/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 25/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 26/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 27/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 28/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 29/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 30/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 31/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 32/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 33/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 34/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 35/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 36/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 37/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 38/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 39/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 40/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 41/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 42/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 43/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 44/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 45/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 46/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 47/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 48/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 49/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n",
      "Epoch 50/50\n",
      "10346/10346 [==============================] - 11s 1ms/sample - loss: 7.8216 - accuracy: 0.0764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e174da590>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data,training_labels,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets predict the model by asking the next word from the given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"So hard to breathe\"\n",
    "text_list=[text]\n",
    "text_seq=token.texts_to_sequences(text_list)\n",
    "text_pad_seq=pad_sequences(text_seq,maxlen=max_length-1,padding='pre')\n",
    "text_pad_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(text_pad_seq).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index={w:i for i,w in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_word=reverse_index[prediction]\n",
    "predict_text=text + ' ' +str(predict_word)\n",
    "print(predict_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets predict the next 50 words from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_words=50\n",
    "text=\"Hello, i am vikas\"\n",
    "text_list=[text]\n",
    "for i in range(50):\n",
    "    #print(text_list)\n",
    "    text_seq=token.texts_to_sequences(text_list)\n",
    "    text_pad_seq=pad_sequences(text_seq,maxlen=max_length-1,padding='pre')\n",
    "    #print(text_pad_seq.shape)\n",
    "    prediction=model.predict(text_pad_seq).argmax()\n",
    "    predict_word=reverse_index[prediction]\n",
    "    text=text + ' ' + str(predict_word)\n",
    "    text_list=[text]\n",
    "    #print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
