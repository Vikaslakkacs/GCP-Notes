{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dropout,Embedding,RepeatVector,TimeDistributed,Dense,GRU\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.GRU(20,return_sequences=True,\n",
    "                                 return_state=True,\n",
    "                                 recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6c4f5c980421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.add(GRU(1024,return_sequences=True,\n\u001b[0;32m----> 4\u001b[0;31m                                  return_state=True))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         raise TypeError('All layers in a Sequential model '\n\u001b[0m\u001b[1;32m    206\u001b[0m                         \u001b[0;34m'should have a single output tensor. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                         \u001b[0;34m'For multi-output layers, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API."
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Embedding(1000,256,input_length=11))\n",
    "model.add(GRU(1024,return_sequences=True,\n",
    "                                 return_state=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[-0.03550946  0.04920404  0.02198812 -0.0211562   0.01972819 -0.00232249\n   0.03370148 -0.01976578 -0.02407695  0.0079691  -0.01598857  0.04174156\n  -0.00119139  0.01201744  0.00661162 -0.00192643 -0.03558575  0.00857948\n  -0.00709351  0.0466128   0.04538092 -0.03526281 -0.01798914  0.02762953\n  -0.0433303  -0.00334481  0.02621213 -0.01461711 -0.03420945 -0.02619069\n   0.00390882 -0.01031554 -0.00391848 -0.00949669 -0.04546785  0.03883466\n   0.00941948  0.04862548 -0.03657644  0.01415474  0.03919287  0.01886605\n  -0.00519631 -0.03432751  0.04496374 -0.01637479 -0.0324802   0.03497601\n  -0.00094485  0.01998675 -0.01916564  0.02563522 -0.02276986 -0.04398785\n   0.03315281 -0.04121119  0.02891937  0.03411785  0.03255583  0.02615223\n   0.04348315  0.03617277 -0.02996656 -0.01763308 -0.03802403 -0.0065437\n  -0.01571454  0.01797253  0.03232441 -0.01761867 -0.01628481  0.01979766\n  -0.04721282 -0.04277717 -0.02557268 -0.03109257  0.00994698  0.04106914\n   0.03181129 -0.0281363  -0.0271505  -0.0193102  -0.01244459 -0.00389256\n  -0.04631629 -0.00917026  0.02350484  0.02770143  0.02540958  0.00226252\n   0.02015091 -0.00892203  0.04515437  0.03665998  0.00822856  0.02180814\n  -0.04169072 -0.01959027 -0.02052618 -0.04117678  0.04655671  0.03920945\n   0.00364181  0.04017976 -0.04415273  0.02351784 -0.0244426   0.0365099\n  -0.02382591 -0.01830377  0.03428037  0.00997784  0.04583846  0.00342803\n  -0.01810473  0.02724459  0.03194091 -0.04890146  0.02428898 -0.00634807\n   0.02811788  0.03573212 -0.01435242 -0.03508117  0.01721705  0.00330763\n   0.04981631 -0.00497324  0.04047384  0.0428786   0.04531424  0.02422119\n   0.00544614 -0.00886701  0.03342878  0.00281787  0.01339689 -0.00749053\n   0.00120398 -0.03483792  0.00197786  0.02534442  0.03234192  0.01872932\n   0.02162061 -0.00892656  0.02598241  0.01068401 -0.00892774 -0.03680885\n  -0.03090179  0.00406124  0.01653567 -0.03911887 -0.04056277 -0.02787703\n  -0.01914116 -0.0315439   0.04254638  0.03530643  0.01881577  0.02573135\n  -0.02144985 -0.01756164  0.02827526 -0.03298267  0.02721882  0.00079257\n   0.02705773  0.04751115 -0.01328614  0.01180898 -0.04863646 -0.03686591\n  -0.0325162  -0.03320211 -0.01316947 -0.0200768   0.0410344  -0.00493941\n   0.0231454  -0.04412755 -0.02871852  0.03500471 -0.04741082  0.04431934\n  -0.02089687  0.00064258  0.04976157 -0.03086928 -0.0339156  -0.04330914\n  -0.00615282 -0.04555514  0.04594496 -0.019045   -0.00054203  0.04081159\n   0.04302975 -0.04627308  0.00014389  0.04604269 -0.03909374 -0.00111014\n  -0.01689199 -0.01312049 -0.00253053  0.0187321   0.0292159   0.00533934\n   0.04585917  0.01526814  0.00455909  0.02415225 -0.01143336 -0.03605763\n  -0.02667105 -0.01809409  0.04298916 -0.03472609 -0.00217953 -0.04454293\n  -0.03719072  0.04811009  0.03639806  0.01915692  0.00384595  0.0089891\n   0.00905844  0.00182124 -0.03059225  0.04050824  0.01071912  0.00669036\n   0.01854118 -0.00888165 -0.04155676 -0.00873194  0.04043731  0.02860447\n  -0.00825812 -0.01499201  0.03429711 -0.02803132 -0.03162805  0.03126527\n   0.04690543 -0.01849985  0.03415617  0.02167214  0.03463345  0.04506144\n  -0.00654231  0.00475359  0.04138098  0.01083276]\n [ 0.04571524  0.01397368 -0.00774617  0.0206092  -0.03341655 -0.00775911\n   0.03280828 -0.01794412  0.00426244  0.03085517 -0.01915745 -0.04913249\n   0.04872913  0.00706502  0.02782496  0.03046011  0.02527389 -0.03960961\n  -0.00309719 -0.03535154  0.02190921 -0.04281139 -0.02235982 -0.00488842\n   0.03364022 -0.01381733  0.00766913  0.04647373 -0.02959394 -0.01999086\n  -0.01495693  0.00625579  0.04041496  0.03542003  0.0054003   0.04635203\n   0.03710592 -0.04070526 -0.03274181 -0.00985197 -0.04061253 -0.02155582\n  -0.01367734  0.01070044  0.03993088 -0.00923502 -0.040211   -0.01018075\n   0.0082685   0.03252121 -0.02897794 -0.03900547  0.00696184  0.0234278\n  -0.00539089 -0.03507636 -0.03075464  0.01680163  0.01832861 -0.02891924\n  -0.0062567   0.04336193 -0.01716187 -0.01125779 -0.01800174 -0.00186982\n   0.01489513 -0.02733746  0.01590883  0.03902042  0.04411501  0.02560012\n  -0.00924003  0.01182095 -0.00131493  0.02464208  0.02813753 -0.03620112\n  -0.00739758 -0.00113835  0.0145591   0.02512624 -0.02814859 -0.00141812\n   0.03411688  0.02367434 -0.04873049  0.03300459  0.04130591 -0.0413555\n  -0.00592631  0.04629469 -0.045565    0.04593498 -0.0443163  -0.00011522\n   0.04015969 -0.00471885  0.02644107 -0.02208196 -0.04419389 -0.01388426\n  -0.04518459  0.01111369  0.00023153 -0.00533225 -0.00930471  0.00681198\n  -0.04153497  0.003845   -0.0229123   0.00440937  0.02960983  0.01458756\n   0.01831812 -0.00362007  0.04063444  0.01036857  0.04170506 -0.01717269\n  -0.01333094  0.02407959 -0.01023362 -0.00037905 -0.03293582 -0.01681668\n  -0.02718602 -0.00803372  0.01343448 -0.01559974  0.00387607  0.03942374\n   0.01802268  0.01299867  0.04726232  0.0217592   0.04711867 -0.00399391\n   0.03898844 -0.01131978 -0.02226775 -0.04041107  0.02252677  0.02238839\n   0.02979492 -0.03486899 -0.00702164 -0.01040918 -0.00321374  0.04083418\n  -0.02574161  0.03260026 -0.03986388 -0.00510146 -0.04880517 -0.00416703\n   0.01486499  0.04266116 -0.01723032 -0.01043637  0.00459945 -0.0088688\n   0.01561766  0.01648429  0.03472984  0.01577256  0.00570639  0.02691466\n   0.04364156 -0.00214627 -0.0125558   0.0124606  -0.0001166   0.02923289\n  -0.03757406 -0.02408934  0.04397664  0.04081321  0.02988416 -0.01581347\n   0.04499621 -0.00020834  0.04512519  0.0197304   0.01936859  0.03412339\n   0.00146108  0.01289698 -0.0057373   0.02873394  0.02167299  0.00549348\n   0.03321889  0.01370478  0.00807257 -0.00612418  0.03341894 -0.04926443\n   0.03332268 -0.0205815   0.03414826  0.00501055  0.00237538 -0.03364879\n   0.04597075 -0.01072185 -0.0378211   0.04151182  0.04502111 -0.03102601\n   0.0190627  -0.00779916  0.01458747  0.00423852 -0.04090686 -0.01889148\n   0.00113896  0.01737363  0.03677628  0.01716546 -0.04511018  0.02906456\n   0.01068459  0.0218781   0.00490339 -0.03686391  0.04808449  0.03444152\n  -0.00023095  0.02017099 -0.00824799  0.03529452  0.02333209  0.04177171\n   0.01714971  0.01792434 -0.03567686 -0.00813647  0.00258118  0.01590666\n   0.01876849 -0.02862785 -0.02878081 -0.04757402  0.03240586  0.04502286\n   0.01083827 -0.00103159 -0.02046121 -0.02537708 -0.02623274 -0.04419886\n  -0.01675038  0.02287875  0.01748744  0.03052337]], shape=(2, 256), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5fb914f9d033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    159\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    160\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: tf.Tensor(\n[[-0.03550946  0.04920404  0.02198812 -0.0211562   0.01972819 -0.00232249\n   0.03370148 -0.01976578 -0.02407695  0.0079691  -0.01598857  0.04174156\n  -0.00119139  0.01201744  0.00661162 -0.00192643 -0.03558575  0.00857948\n  -0.00709351  0.0466128   0.04538092 -0.03526281 -0.01798914  0.02762953\n  -0.0433303  -0.00334481  0.02621213 -0.01461711 -0.03420945 -0.02619069\n   0.00390882 -0.01031554 -0.00391848 -0.00949669 -0.04546785  0.03883466\n   0.00941948  0.04862548 -0.03657644  0.01415474  0.03919287  0.01886605\n  -0.00519631 -0.03432751  0.04496374 -0.01637479 -0.0324802   0.03497601\n  -0.00094485  0.01998675 -0.01916564  0.02563522 -0.02276986 -0.04398785\n   0.03315281 -0.04121119  0.02891937  0.03411785  0.03255583  0.02615223\n   0.04348315  0.03617277 -0.02996656 -0.01763308 -0.03802403 -0.0065437\n  -0.01571454  0.01797253  0.03232441 -0.01761867 -0.01628481  0.01979766\n  -0.04721282 -0.04277717 -0.02557268 -0.03109257  0.00994698  0.04106914\n   0.03181129 -0.0281363  -0.0271505  -0.0193102  -0.01244459 -0.00389256\n  -0.04631629 -0.00917026  0.02350484  0.02770143  0.02540958  0.00226252\n   0.02015091 -0.00892203  0.04515437  0.03665998  0.00822856  0.02180814\n  -0.04169072 -0.01959027 -0.02052618 -0.04117678  0.04655671  0.03920945\n   0.00364181  0.04017976 -0.04415273  0.02351784 -0.0244426   0.0365099\n  -0.02382591 -0.01830377  0.03428037  0.00997784  0.04583846  0.00342803\n  -0.01810473  0.02724459  0.03194091 -0.04890146  0.02428898 -0.00634807\n   0.02811788  0.03573212 -0.01435242 -0.03508117  0.01721705  0.00330763\n   0.04981631 -0.00497324  0.04047384  0.0428786   0.04531424  0.02422119\n   0.00544614 -0.00886701  0.03342878  0.00281787  0.01339689 -0.00749053\n   0.00120398 -0.03483792  0.00197786  0.02534442  0.03234192  0.01872932\n   0.02162061 -0.00892656  0.02598241  0.01068401 -0.00892774 -0.03680885\n  -0.03090179  0.00406124  0.01653567 -0.03911887 -0.04056277 -0.02787703\n  -0.01914116 -0.0315439   0.04254638  0.03530643  0.01881577  0.02573135\n  -0.02144985 -0.01756164  0.02827526 -0.03298267  0.02721882  0.00079257\n   0.02705773  0.04751115 -0.01328614  0.01180898 -0.04863646 -0.03686591\n  -0.0325162  -0.03320211 -0.01316947 -0.0200768   0.0410344  -0.00493941\n   0.0231454  -0.04412755 -0.02871852  0.03500471 -0.04741082  0.04431934\n  -0.02089687  0.00064258  0.04976157 -0.03086928 -0.0339156  -0.04330914\n  -0.00615282 -0.04555514  0.04594496 -0.019045   -0.00054203  0.04081159\n   0.04302975 -0.04627308  0.00014389  0.04604269 -0.03909374 -0.00111014\n  -0.01689199 -0.01312049 -0.00253053  0.0187321   0.0292159   0.00533934\n   0.04585917  0.01526814  0.00455909  0.02415225 -0.01143336 -0.03605763\n  -0.02667105 -0.01809409  0.04298916 -0.03472609 -0.00217953 -0.04454293\n  -0.03719072  0.04811009  0.03639806  0.01915692  0.00384595  0.0089891\n   0.00905844  0.00182124 -0.03059225  0.04050824  0.01071912  0.00669036\n   0.01854118 -0.00888165 -0.04155676 -0.00873194  0.04043731  0.02860447\n  -0.00825812 -0.01499201  0.03429711 -0.02803132 -0.03162805  0.03126527\n   0.04690543 -0.01849985  0.03415617  0.02167214  0.03463345  0.04506144\n  -0.00654231  0.00475359  0.04138098  0.01083276]\n [ 0.04571524  0.01397368 -0.00774617  0.0206092  -0.03341655 -0.00775911\n   0.03280828 -0.01794412  0.00426244  0.03085517 -0.01915745 -0.04913249\n   0.04872913  0.00706502  0.02782496  0.03046011  0.02527389 -0.03960961\n  -0.00309719 -0.03535154  0.02190921 -0.04281139 -0.02235982 -0.00488842\n   0.03364022 -0.01381733  0.00766913  0.04647373 -0.02959394 -0.01999086\n  -0.01495693  0.00625579  0.04041496  0.03542003  0.0054003   0.04635203\n   0.03710592 -0.04070526 -0.03274181 -0.00985197 -0.04061253 -0.02155582\n  -0.01367734  0.01070044  0.03993088 -0.00923502 -0.040211   -0.01018075\n   0.0082685   0.03252121 -0.02897794 -0.03900547  0.00696184  0.0234278\n  -0.00539089 -0.03507636 -0.03075464  0.01680163  0.01832861 -0.02891924\n  -0.0062567   0.04336193 -0.01716187 -0.01125779 -0.01800174 -0.00186982\n   0.01489513 -0.02733746  0.01590883  0.03902042  0.04411501  0.02560012\n  -0.00924003  0.01182095 -0.00131493  0.02464208  0.02813753 -0.03620112\n  -0.00739758 -0.00113835  0.0145591   0.02512624 -0.02814859 -0.00141812\n   0.03411688  0.02367434 -0.04873049  0.03300459  0.04130591 -0.0413555\n  -0.00592631  0.04629469 -0.045565    0.04593498 -0.0443163  -0.00011522\n   0.04015969 -0.00471885  0.02644107 -0.02208196 -0.04419389 -0.01388426\n  -0.04518459  0.01111369  0.00023153 -0.00533225 -0.00930471  0.00681198\n  -0.04153497  0.003845   -0.0229123   0.00440937  0.02960983  0.01458756\n   0.01831812 -0.00362007  0.04063444  0.01036857  0.04170506 -0.01717269\n  -0.01333094  0.02407959 -0.01023362 -0.00037905 -0.03293582 -0.01681668\n  -0.02718602 -0.00803372  0.01343448 -0.01559974  0.00387607  0.03942374\n   0.01802268  0.01299867  0.04726232  0.0217592   0.04711867 -0.00399391\n   0.03898844 -0.01131978 -0.02226775 -0.04041107  0.02252677  0.02238839\n   0.02979492 -0.03486899 -0.00702164 -0.01040918 -0.00321374  0.04083418\n  -0.02574161  0.03260026 -0.03986388 -0.00510146 -0.04880517 -0.00416703\n   0.01486499  0.04266116 -0.01723032 -0.01043637  0.00459945 -0.0088688\n   0.01561766  0.01648429  0.03472984  0.01577256  0.00570639  0.02691466\n   0.04364156 -0.00214627 -0.0125558   0.0124606  -0.0001166   0.02923289\n  -0.03757406 -0.02408934  0.04397664  0.04081321  0.02988416 -0.01581347\n   0.04499621 -0.00020834  0.04512519  0.0197304   0.01936859  0.03412339\n   0.00146108  0.01289698 -0.0057373   0.02873394  0.02167299  0.00549348\n   0.03321889  0.01370478  0.00807257 -0.00612418  0.03341894 -0.04926443\n   0.03332268 -0.0205815   0.03414826  0.00501055  0.00237538 -0.03364879\n   0.04597075 -0.01072185 -0.0378211   0.04151182  0.04502111 -0.03102601\n   0.0190627  -0.00779916  0.01458747  0.00423852 -0.04090686 -0.01889148\n   0.00113896  0.01737363  0.03677628  0.01716546 -0.04511018  0.02906456\n   0.01068459  0.0218781   0.00490339 -0.03686391  0.04808449  0.03444152\n  -0.00023095  0.02017099 -0.00824799  0.03529452  0.02333209  0.04177171\n   0.01714971  0.01792434 -0.03567686 -0.00813647  0.00258118  0.01590666\n   0.01876849 -0.02862785 -0.02878081 -0.04757402  0.03240586  0.04502286\n   0.01083827 -0.00103159 -0.02046121 -0.02537708 -0.02623274 -0.04419886\n  -0.01675038  0.02287875  0.01748744  0.03052337]], shape=(2, 256), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "embed=Embedding(1000,256)\n",
    "model.add(embed(x))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.uniform((64,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
