{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb,info=tfds.load('imdb_reviews',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch,test_batch=imdb['train'], imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "training_text,training_label=[],[]\n",
    "for text,label in train_batch:\n",
    "    training_text.append(str(text.numpy()))\n",
    "    training_label.append(label.numpy())\n",
    "    print(label)\n",
    "    print(type(label))\n",
    "    break\n",
    "## Testing data\n",
    "testing_text,testing_label=[],[]\n",
    "for text,label in test_batch:\n",
    "    testing_text.append(str(text.numpy()))\n",
    "    testing_label.append(label.numpy())\n",
    "    print(label)\n",
    "    print(type(label))\n",
    "    break\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor to numpy conversion of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numpy_label=np.array(training_label)\n",
    "test_numpy_label=np.array(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=10000\n",
    "embed_dim=16\n",
    "padding='post'\n",
    "oov_text='<OOV>'\n",
    "max_length=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(num_words=num_words,oov_token=oov_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq=token.texts_to_sequences(training_text)\n",
    "test_seq=token.texts_to_sequences(testing_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad_seq=pad_sequences(train_seq,maxlen=max_length,padding=padding,truncating='post')\n",
    "test_pad_seq=pad_sequences(test_seq,maxlen=max_length,padding=padding,truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 120)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding,Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Embedding(input_dim=num_words,output_dim=embed_dim,input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=6,activation=tf.nn.relu))\n",
    "model.add(Dense(units=1,activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 10s 390us/sample - loss: 0.4952 - accuracy: 0.7416 - val_loss: 0.4008 - val_accuracy: 0.8168\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 9s 372us/sample - loss: 0.2414 - accuracy: 0.9066 - val_loss: 0.4161 - val_accuracy: 0.8178\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 8s 335us/sample - loss: 0.0958 - accuracy: 0.9749 - val_loss: 0.5117 - val_accuracy: 0.8040\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 9s 368us/sample - loss: 0.0228 - accuracy: 0.9971 - val_loss: 0.6025 - val_accuracy: 0.8063\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 9s 364us/sample - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.6810 - val_accuracy: 0.8074\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 9s 344us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8070\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 9s 371us/sample - loss: 8.6722e-04 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.8087\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 8s 339us/sample - loss: 4.7973e-04 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.8083\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 9s 377us/sample - loss: 2.7663e-04 - accuracy: 1.0000 - val_loss: 0.8888 - val_accuracy: 0.8090\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 8s 324us/sample - loss: 1.6518e-04 - accuracy: 1.0000 - val_loss: 0.9343 - val_accuracy: 0.8088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa747432d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_seq,train_numpy_label,epochs=10,validation_data=(test_pad_seq,test_numpy_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=['This is a worst movie i have ever seen. i do not recommend this movie at all']\n",
    "#prediction=['A Feel good movie where all the family can go and enjoy together.']\n",
    "prediction=[\"An Extra-ordinary movie. The director is awesome. I will recommend this movie\"]\n",
    "prediction=[\"Iron Man 2 was the perfect sequel to the first Iron Man film. The film was a combination of both humour and action which is what I love about it. The film has some of the best CGI I have ever seen. Robert Downey Jr was the perfect actor to play Iron Man. The film wasn't as great as the first film but I still enjoyed itThank you Robert Downey Jr and Marvel Studios for making the perfect sequel to my favourite film.RIP Tony Stark 😭😭😭\"]\n",
    "prediction=[\"And the hits (maybe not!) keep on coming w/this recent remake of Hugh Lofting's beloved character. Having seen the bloated 1967 (& yet Best Picture nominee) original w/Rex Harrison not long ago, this update should've been a walk in the park but within minutes you can see where the CGI ran away w/the production (topping at nearly 180 million dollars) where anthropomorphized animals look the part but sound way too contemporary for their own good (Godfather references!). Robert Downey Jr. is getting some heat here but there are many at the table to point at. Yes I'd like the writer of Traffic (Steven Gaghan who won the Oscar for that script) & the director of the searing drama Syriana to direct a kiddie friendly comedy. Maybe Scorsese can tackle another Casper the Friendly Ghost adventure while we're at it. This hurt!\"]\n",
    "prediction=token.texts_to_sequences(prediction)\n",
    "prediction_pad_seq=pad_sequences(prediction,maxlen=max_length,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pad_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(prediction_pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We wil try with a new model using Average global pooling instead of Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 160,091\n",
      "Trainable params: 160,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Embedding(input_dim=num_words,output_dim=embed_dim,input_length=max_length))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(units=5,activation=tf.nn.relu))\n",
    "model.add(Dense(units=1,activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer='adam',loss=keras.losses.BinaryCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 9s 357us/sample - loss: 0.6918 - accuracy: 0.4998 - val_loss: 0.6712 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 8s 325us/sample - loss: 0.6423 - accuracy: 0.6605 - val_loss: 0.6280 - val_accuracy: 0.7411\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 11s 444us/sample - loss: 0.6060 - accuracy: 0.8204 - val_loss: 0.6072 - val_accuracy: 0.8050\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 11s 436us/sample - loss: 0.5841 - accuracy: 0.8626 - val_loss: 0.5969 - val_accuracy: 0.8076\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 10s 406us/sample - loss: 0.5695 - accuracy: 0.8850 - val_loss: 0.5914 - val_accuracy: 0.8131\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 10s 380us/sample - loss: 0.5592 - accuracy: 0.9006 - val_loss: 0.5883 - val_accuracy: 0.8227\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 10s 399us/sample - loss: 0.5512 - accuracy: 0.9135 - val_loss: 0.5870 - val_accuracy: 0.8206\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 11s 458us/sample - loss: 0.5450 - accuracy: 0.9227 - val_loss: 0.5871 - val_accuracy: 0.8118\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 9s 358us/sample - loss: 0.5400 - accuracy: 0.9308 - val_loss: 0.5867 - val_accuracy: 0.8218\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 10s 418us/sample - loss: 0.5361 - accuracy: 0.9372 - val_loss: 0.5869 - val_accuracy: 0.8194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa7447f250>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_seq,train_numpy_label,epochs=10,validation_data=(test_pad_seq,test_numpy_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
