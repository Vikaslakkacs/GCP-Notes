{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb,info=tfds.load('imdb_reviews',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch,test_batch=imdb['train'],imdb['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cat,training_label=[],[]\n",
    "testing_cat,testing_label=[],[]\n",
    "for cat,label in train_batch:\n",
    "    training_cat.append(str(cat.numpy()))\n",
    "    training_label.append(label.numpy())\n",
    "    \n",
    "for cat,label in test_batch:\n",
    "    testing_cat.append(str(cat.numpy()))\n",
    "    testing_label.append(label.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label conversion to numpy\n",
    "training_label=np.array(training_label)\n",
    "testing_label=np.array(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cat[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameters\n",
    "vocab_size=10000\n",
    "embedded_dim=16\n",
    "truncating='post'\n",
    "oov_name='<OOV>'\n",
    "max_word_len=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(vocab_size,oov_token=oov_name)\n",
    "token.fit_on_texts(training_cat)\n",
    "word_index=token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['fellow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq=token.texts_to_sequences(training_cat)\n",
    "test_seq=token.texts_to_sequences(testing_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad_seq=pad_sequences(train_seq,maxlen=max_word_len,padding='post',truncating=truncating)\n",
    "test_pad_seq=pad_sequences(test_seq,maxlen=max_word_len,padding='post',truncating=truncating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 120)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 6175,    2,    1, 4916, 4029,    9,    4,  912, 1622,    3,\n",
       "       1969, 1307,    3, 2384, 8836,  201,  746,  361,   15,   34,  208,\n",
       "        308,    6,   83,    8,    8,   19,  214,   22,  352,    4,    1,\n",
       "        990,    2,   82,    5, 3608,  545,    1,    6,    1,  539,    4,\n",
       "          1,  434,    4,    1,    3,    6,    1,    2, 1176,  539,   95,\n",
       "          1, 8111,   10,   46,   22,    2, 1996,   16, 1153,    5,    2,\n",
       "        511,    8,    8,  163,   62, 2624, 7315,   13,  586,   22,    2,\n",
       "       2297,  507,    5,    2, 3652,  317,    2,    1, 1835, 3445,  451,\n",
       "       4030,    3, 1168,  985,    6,   28, 4091, 3608,  545,   16,    1,\n",
       "          2, 2297, 2430,   16,    2,  299, 1357, 1259,    8,    8, 2297,\n",
       "        803,   29, 2871,   16,    4,    1, 3028,  564,    5,  746],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_seq[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=embedded_dim,input_length=max_word_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=6,activation=tf.nn.relu))\n",
    "model.add(Dense(units=1,activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                           metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call backs\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if logs.get('accuracy')>0.80:\n",
    "            print('\\n')\n",
    "            print('Crossed 80% accuracy. Stopping training')\n",
    "            self.model_stop_training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.6323 - accuracy: 0.6976\n",
      "\n",
      "Crossed 80% accuracy. Stopping training\n",
      "25000/25000 [==============================] - 11s 436us/sample - loss: 0.6323 - accuracy: 0.6976 - val_loss: 0.5907 - val_accuracy: 0.8079\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 9s 353us/sample - loss: 0.5614 - accuracy: 0.8767 - val_loss: 0.5886 - val_accuracy: 0.8206\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 8s 333us/sample - loss: 0.5405 - accuracy: 0.9238 - val_loss: 0.5881 - val_accuracy: 0.8108\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 9s 356us/sample - loss: 0.5287 - accuracy: 0.9477 - val_loss: 0.5896 - val_accuracy: 0.8080\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 10s 407us/sample - loss: 0.5227 - accuracy: 0.9588 - val_loss: 0.5923 - val_accuracy: 0.8148\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 9s 346us/sample - loss: 0.5195 - accuracy: 0.9651 - val_loss: 0.5950 - val_accuracy: 0.8148\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 8s 337us/sample - loss: 0.5177 - accuracy: 0.9688 - val_loss: 0.5925 - val_accuracy: 0.8094\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 10s 403us/sample - loss: 0.5163 - accuracy: 0.9719 - val_loss: 0.5950 - val_accuracy: 0.8082\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 9s 350us/sample - loss: 0.5151 - accuracy: 0.9745 - val_loss: 0.5946 - val_accuracy: 0.8056\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 9s 347us/sample - loss: 0.5143 - accuracy: 0.9760 - val_loss: 0.5944 - val_accuracy: 0.8032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9973c71850>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_seq,training_label,epochs=10,validation_data=(test_pad_seq,testing_label),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
