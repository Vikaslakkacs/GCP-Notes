{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Implementation\n",
    "| A | B | A XOR B |\n",
    "|---|---|---------|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "\n",
    "XOR Cipher encryption method is basically used to encrypt data which is hard to crack with brute force method, i.e., by generating random encryption keys which match the appropriate key.\n",
    "\n",
    "The concept of implementation with XOR Cipher is to define a XOR encryption key and then perform XOR operation of the characters in the specified string with this key, which a user tries to encrypt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Hyp: [[0.33834038]\n",
      " [0.32305655]\n",
      " [0.28128275]\n",
      " [0.27466667]]\n",
      "Epoch: 100\n",
      "Hyp: [[0.07020838]\n",
      " [0.94336384]\n",
      " [0.90183151]\n",
      " [0.05780741]]\n",
      "Epoch: 200\n",
      "Hyp: [[0.01840956]\n",
      " [0.98368706]\n",
      " [0.97499923]\n",
      " [0.01549931]]\n",
      "Epoch: 300\n",
      "Hyp: [[0.01030334]\n",
      " [0.990706  ]\n",
      " [0.98602492]\n",
      " [0.00874173]]\n",
      "Epoch: 400\n",
      "Hyp: [[0.00710821]\n",
      " [0.99353728]\n",
      " [0.99034778]\n",
      " [0.00605789]]\n",
      "Epoch: 500\n",
      "Hyp: [[0.00541141]\n",
      " [0.99505722]\n",
      " [0.99264137]\n",
      " [0.00462613]]\n",
      "Epoch: 600\n",
      "Hyp: [[0.00436254]\n",
      " [0.99600288]\n",
      " [0.99405956]\n",
      " [0.00373826]]\n",
      "Epoch: 700\n",
      "Hyp: [[0.00365121]\n",
      " [0.99664704]\n",
      " [0.99502199]\n",
      " [0.00313463]]\n",
      "Epoch: 800\n",
      "Hyp: [[0.00313758]\n",
      " [0.99711364]\n",
      " [0.99571743]\n",
      " [0.00269791]]\n",
      "Epoch: 900\n",
      "Hyp: [[0.00274958]\n",
      " [0.99746698]\n",
      " [0.99624322]\n",
      " [0.00236745]]\n"
     ]
    }
   ],
   "source": [
    "#Declaring necessary modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "A simple numpy implementation of a XOR gate to understand the backpropagation\n",
    "algorithm\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.float64,shape = [4,2],name = \"x\")\n",
    "#declaring a place holder for input x\n",
    "y = tf.placeholder(tf.float64,shape = [4,1],name = \"y\")\n",
    "#declaring a place holder for desired output y\n",
    "\n",
    "m = np.shape(x)[0]#number of training examples\n",
    "n = np.shape(x)[1]#number of features\n",
    "hidden_s = 2 #number of nodes in the hidden layer\n",
    "l_r = 1#learning rate initialization\n",
    "\n",
    "theta1 = tf.cast(tf.Variable(tf.random_normal([3,hidden_s]),name = \"theta1\"),tf.float64)\n",
    "theta2 = tf.cast(tf.Variable(tf.random_normal([hidden_s+1,1]),name = \"theta2\"),tf.float64)\n",
    "\n",
    "#conducting forward propagation\n",
    "a1 = tf.concat([np.c_[np.ones(x.shape[0])],x],1)\n",
    "#the weights of the first layer are multiplied by the input of the first layer\n",
    "\n",
    "z1 = tf.matmul(a1,theta1)\n",
    "#the input of the second layer is the output of the first layer, passed through the activation function and column of biases is added\n",
    "\n",
    "a2 = tf.concat([np.c_[np.ones(x.shape[0])],tf.sigmoid(z1)],1)\n",
    "#the input of the second layer is multiplied by the weights\n",
    "\n",
    "z3 = tf.matmul(a2,theta2)\n",
    "#the output is passed through the activation function to obtain the final probability\n",
    "\n",
    "h3 = tf.sigmoid(z3)\n",
    "cost_func = -tf.reduce_sum(y*tf.log(h3)+(1-y)*tf.log(1-h3),axis = 1)\n",
    "\n",
    "#built in tensorflow optimizer that conducts gradient descent using specified learning rate to obtain theta values\n",
    "\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate = l_r).minimize(cost_func)\n",
    "\n",
    "#setting required X and Y values to perform XOR operation\n",
    "X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "Y = [[0],[1],[1],[0]]\n",
    "\n",
    "#initializing all variables, creating a session and running a tensorflow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#running gradient descent for each iteration and printing the hypothesis obtained using the updated theta values\n",
    "for i in range(1000):\n",
    "   sess.run(optimiser, feed_dict = {x:X,y:Y})#setting place holder values using feed_dict\n",
    "   if i%100==0:\n",
    "      print(\"Epoch:\",i)\n",
    "      print(\"Hyp:\",sess.run(h3,feed_dict = {x:X,y:Y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical NOT operator\n",
    "X = [[0.], [1.]]\n",
    "Y = [[1.], [0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.00023 -- iter: 2/2\n",
      "Testing NOT operator\n",
      "NOT 0: [[0.98522264]]\n",
      "NOT 1: [[0.0116728]]\n"
     ]
    }
   ],
   "source": [
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 1])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing NOT operator\")\n",
    "    print(\"NOT 0:\", m.predict([[0.]]))\n",
    "    print(\"NOT 1:\", m.predict([[1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.00072 -- iter: 4/4\n",
      "Testing OR operator\n",
      "0 or 0: [[0.0274915]]\n",
      "0 or 1: [[0.9841086]]\n",
      "1 or 0: [[0.98131174]]\n",
      "1 or 1: [[0.9999913]]\n"
     ]
    }
   ],
   "source": [
    "# Logical OR operator\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y = [[0.], [1.], [1.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing OR operator\")\n",
    "    print(\"0 or 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 or 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 or 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 or 1:\", m.predict([[1., 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.00357\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.00357 -- iter: 4/4\n",
      "Testing AND operator\n",
      "0 and 0: [[3.545785e-05]]\n",
      "0 and 1: [[0.03029223]]\n",
      "1 and 0: [[0.03084874]]\n",
      "1 and 1: [[0.96556705]]\n"
     ]
    }
   ],
   "source": [
    "# Logical AND operator\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y = [[0.], [0.], [0.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing AND operator\")\n",
    "    print(\"0 and 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 and 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 and 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 and 1:\", m.predict([[1., 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.82165\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD_0 | epoch: 400 | loss: 0.41131 -- iter: 4/4\n",
      "| SGD_1 | epoch: 400 | loss: 0.41035 -- iter: 4/4\n",
      "Testing XOR operator\n",
      "0 xor 0: [[0.00049382]]\n",
      "0 xor 1: [[0.99822605]]\n",
      "1 xor 0: [[0.9981604]]\n",
      "1 xor 1: [[0.0010094]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Going further: Graph combination with multiple optimizers\n",
    "Create a XOR operator using product of NAND and OR operators\n",
    "'''\n",
    "# Data\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y_nand = [[1.], [1.], [1.], [0.]]\n",
    "Y_or = [[0.], [1.], [1.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    # Building a network with 2 optimizers\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    # Nand operator definition\n",
    "    g_nand = tflearn.fully_connected(g, 32, activation='linear')\n",
    "    g_nand = tflearn.fully_connected(g_nand, 32, activation='linear')\n",
    "    g_nand = tflearn.fully_connected(g_nand, 1, activation='sigmoid')\n",
    "    g_nand = tflearn.regression(g_nand, optimizer='sgd',\n",
    "                                learning_rate=2.,\n",
    "                                loss='binary_crossentropy')\n",
    "    # Or operator definition\n",
    "    g_or = tflearn.fully_connected(g, 32, activation='linear')\n",
    "    g_or = tflearn.fully_connected(g_or, 32, activation='linear')\n",
    "    g_or = tflearn.fully_connected(g_or, 1, activation='sigmoid')\n",
    "    g_or = tflearn.regression(g_or, optimizer='sgd',\n",
    "                              learning_rate=2.,\n",
    "                              loss='binary_crossentropy')\n",
    "    # XOR merging Nand and Or operators\n",
    "    g_xor = tflearn.merge([g_nand, g_or], mode='elemwise_mul')\n",
    "\n",
    "    # Training\n",
    "    m = tflearn.DNN(g_xor)\n",
    "    m.fit(X, [Y_nand, Y_or], n_epoch=400, snapshot_epoch=False)\n",
    "\n",
    "    # Testing\n",
    "    print(\"Testing XOR operator\")\n",
    "    print(\"0 xor 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 xor 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 xor 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 xor 1:\", m.predict([[1., 1.]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
