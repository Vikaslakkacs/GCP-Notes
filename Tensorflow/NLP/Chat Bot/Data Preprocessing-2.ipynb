{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=open('movie_lines.txt',encoding='utf-8',errors='ignore').read()\n",
    "conversation=open('movie_conversations.txt',encoding='utf-8',errors='ignore').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines.split('\\n')\n",
    "conversation=conversation.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-1:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create a dict with only line id and line text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_id={}\n",
    "for each_line in lines:\n",
    "    line_descr = each_line.split(' +++$+++ ')\n",
    "    if len(line_descr) == 5:\n",
    "        line_id[line_descr[0]] = line_descr[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They do not!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_id['L1045']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_with_line_id=[]\n",
    "for convo in conversation:\n",
    "    convo_list=convo.split(' +++$+++ ')\n",
    "    if len(convo_list) == 4:\n",
    "        convo_with_line_id.append(convo_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['L194', 'L195', 'L196', 'L197']\",\n",
       " \"['L198', 'L199']\",\n",
       " \"['L200', 'L201', 'L202', 'L203']\",\n",
       " \"['L204', 'L205', 'L206']\",\n",
       " \"['L207', 'L208']\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_line_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE will clean all those string related in the above list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_with_line_id_refined=[]\n",
    "for convo_list in convo_with_line_id:\n",
    "    #removingthe quote and list symbols\n",
    "    trimming=convo_list[2:-2]\n",
    "    #print(trimming)\n",
    "    trimming=trimming.replace(\"'\", \"\")\n",
    "    individual_lines=trimming.replace(\" \",\"\")\n",
    "    #print(individual_lines)\n",
    "    individual_lines=individual_lines.split(',')\n",
    "    #print(individual_lines)\n",
    "    convo_with_line_id_refined.append(individual_lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208']]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_line_id_refined[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have got the list of conversations and lineids related to convos. Now we will create questions and answers from these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[]\n",
    "answers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo_list in convo_with_line_id_refined:\n",
    "    for line_code in range(len(convo_list)-1):\n",
    "        questions.append(line_id[convo_list[line_code]])\n",
    "        answers.append(line_id[convo_list[line_code +1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       " 'Not the hacking and gagging and spitting part.  Please.',\n",
       " \"You're asking me out.  That's so cute. What's your name again?\",\n",
       " \"No, no, it's my fault -- we didn't have a proper introduction ---\",\n",
       " 'Cameron.',\n",
       " \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\",\n",
       " 'Why?',\n",
       " 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.',\n",
       " 'Gosh, if only we could find Kat a boyfriend...']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got questions and answers. Now we have to clean the data formm Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    #lower case\n",
    "    text=text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\",text)\n",
    "    text= re.sub(r\"he's\",\"he is\",text)\n",
    "    text=re.sub(r\"she's\", \"she is\",text)\n",
    "    text=re.sub(r\"that's\",\"that is\",text)\n",
    "    text=re.sub(r\"what's\",\"what is\",text)\n",
    "    text=re.sub(r\"where's\",\"where is\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will\",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have\",text)\n",
    "    text=re.sub(r\"\\'d'\",\" would\",text)\n",
    "    text=re.sub(r\"\\'re\",\" are\",text)\n",
    "    text=re.sub(r\"won't\",\"will not\",text)\n",
    "    text=re.sub(r\"can't\",\"cannot\",text)\n",
    "    text=re.sub(r\"how'd\",\"how would\",text)\n",
    "    text=re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,]\",\"\",text)\n",
    "    #3 We will remove some extra spaces\n",
    "    text=text.replace(5*' ',' ')\n",
    "    text=text.replace(4*' ',' ')\n",
    "    text=text.replace(3*' ',' ')\n",
    "    text=text.replace(2*' ',' ')\n",
    "    #print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques=[]\n",
    "clean_ans=[]\n",
    "for text in questions:\n",
    "    #print(text)\n",
    "    clean_text=clean_data(text)\n",
    "    clean_ques.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in answers:\n",
    "    \n",
    "    clean_text=clean_data(text)\n",
    "    #print(text)\n",
    "    clean_ans.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine i see that i am a prisoner in my own house i am not a daughter i am a possession!',\n",
       " \"i have a date daddy and he ' s not a captain of oppression like some men we know\",\n",
       " \"didn't have you pegged for a gigglepuss fan aren't they a little too preteen bellybutton ring for you\",\n",
       " 'fan of a fan you see a couple of minors come in',\n",
       " 'never',\n",
       " 'padua girls one tall decent body the other one kinda short and undersexed',\n",
       " \"just sent 'em through\",\n",
       " 'so they tell me',\n",
       " \"c'mon i am supposed to give you the tour\",\n",
       " 'north actually how would you ']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ans[125:135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will take words and give them a unique id of allthe words\n",
    "#### For that we get all the words and their count from questions and answers and then removeless frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordscount={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in wordscount:\n",
    "            wordscount[word] = 1\n",
    "        else:\n",
    "            wordscount[word] += 1\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in wordscount:\n",
    "            wordscount[word] = 1\n",
    "        else:\n",
    "            wordscount[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will take out the less frequent words from the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=20\n",
    "word_filetered_words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,count, in wordscount.items():\n",
    "    if count > threshold:\n",
    "        word_filetered_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can', 'we', 'make', 'this', 'quick', 'and', 'andrew', 'are', 'having', 'an']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_filetered_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have all the unique words and we will assign unique id's to all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_id={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=0\n",
    "for word in word_filetered_words:\n",
    "    unique_word_id[word] = word_count\n",
    "    word_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_id['fine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create tokens and we will assign to unique id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "for token in tokens:\n",
    "    unique_word_id[token] =len(unique_word_id) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8554"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_id['<SOS>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create two identiacal dicts from the above dict as we need to make some different changes according to question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ans=unique_word_id\n",
    "unique_ques=unique_word_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will append EOS string to every end of answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_append_ans=[]\n",
    "for sentence in clean_ans:\n",
    "    eos_append_ans.append(sentence+' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"well i thought we'd start with pronunciation if that is okay with you <EOS>\",\n",
       " 'not the hacking and gagging and spitting part please <EOS>',\n",
       " \"okay then how 'bout we try out some french cuisine saturday night <EOS>\",\n",
       " 'forget it <EOS>',\n",
       " 'cameron <EOS>',\n",
       " 'the thing is cameron i am at the mercy of a particularly hideous breed of loser my sister i cannot date until she does <EOS>',\n",
       " 'seems like she could get a date easy enough <EOS>',\n",
       " 'unsolved mystery she used to be really popular when she started high school then it was just like she got sick of it or something <EOS>',\n",
       " 'that is a shame <EOS>',\n",
       " 'let me see what i can do <EOS>']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_append_ans[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We now will convert the question and answer to integers as we have the reference of words to integers and if we find any word which is not present(Because we have removed some non-frequent words) we will replace that with the id of OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ques=[]\n",
    "num_ans=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in clean_ques:\n",
    "    ints=[]\n",
    "    for word in sentence.split():\n",
    "        if word not in unique_ques:\n",
    "            ints.append(unique_ques['<OUT>'])\n",
    "        else:\n",
    "            ints.append(unique_ques[word])\n",
    "    num_ques.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we will loop the eos_append_ans as we have added EOS\n",
    "for sentence in eos_append_ans:\n",
    "    ints=[]\n",
    "    for word in sentence.split():\n",
    "        if word not in unique_ans:\n",
    "            ints.append(unique_ans['<OUT>'])\n",
    "        else:\n",
    "            ints.append(unique_ans[word])\n",
    "    num_ans.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[245, 74, 8552]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ans[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have converted the words into unique integers.\n",
    "### Before training we will sort the lists from less words to more words\n",
    "#### For quicker training we will avoid sentences which has words more than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ques=[]\n",
    "sorted_ans=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,31):\n",
    "        for index,sentence in enumerate(num_ques):\n",
    "             if len(sentence) == i:\n",
    "                    sorted_ques.append(num_ques[index])\n",
    "                    sorted_ans.append(num_ans[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ques[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 48,\n",
       " 25,\n",
       " 47,\n",
       " 18,\n",
       " 49,\n",
       " 50,\n",
       " 15,\n",
       " 51,\n",
       " 52,\n",
       " 45,\n",
       " 53,\n",
       " 8553,\n",
       " 54,\n",
       " 52,\n",
       " 55,\n",
       " 41,\n",
       " 56,\n",
       " 18,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 8552]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
