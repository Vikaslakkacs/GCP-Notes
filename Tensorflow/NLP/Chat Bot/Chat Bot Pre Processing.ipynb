{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will pre process the data first\n",
    "### Steps involved in data preprocessing\n",
    "#### 1. Take the convo lines and convo ids which has the list of lines                         Each convo id is a conversation in the scene which has multiple lines. These           lines are list of line id (like foreign key to convo lines file).\n",
    "#### 2. Take of the delimeter from both files and take only Convo id, line id and line         text.\n",
    "#### 3. Based on the Covo Id list of lines  and line ID line text, we will create two           files . One file is questions: Which has all the lines. Another file is answers         which has all the lines except first line(Where first line is a question). This         answer woould be sent as input or as hidden state while training.\n",
    "#### 4. We will do some data cleaning, where we will replace short words into actual           words. eg: replace wern't to were not. wouldn't to would not etc. and take of           the special characters like +,-,*,/,-,),(etc., except ! and ? where these are           used to detect the sentiment analysis.\n",
    "#### 5. Take the count of the words in both questions and answers (Usually both are             same. Need to find the purpose).\n",
    "#### 6. Tokenization and non-frequent words: these 2 are the important concepts                 We will remove non-frequent words from the wordcount dict. We have a threshold         for the count(eg: words less than 20 occurances can  be discarded), WE will             create  questionwordcount and answerwordcount dicts from this.                         Tokenization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will read movie lines and conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=open('movie_lines.txt', encoding='utf-8', errors='ignore').read()\n",
    "lines=lines.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=open('movie_conversations.txt', encoding='utf-8', errors='ignore').read()\n",
    "conversation=conversation.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines have line Id and text in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L281 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Where?\n"
     ]
    }
   ],
   "source": [
    "print(lines[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation has the list of lines which represents a conversation\n",
    "### These conversation has Ids and lis of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u4 +++$+++ m0 +++$+++ ['L589', 'L590', 'L591']\n"
     ]
    }
   ],
   "source": [
    "print(conversation[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will create a dictionary which matches Lines and Conversation Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    # Each line has 5 elements we will make sure we have 5 elements in the list.\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They do not!\n"
     ]
    }
   ],
   "source": [
    "print(id2line['L1045'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We got the lines and now we will get the conversations into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_id=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last row of conversation is empty s owe discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for details in conversation[:-1]:\n",
    "    #WE get the last part, so we will split the data , FYI the last part is a list of \n",
    "    # lines\n",
    "    _conversation_list = details.split(' +++$+++ ')[-1]\n",
    "    # We got the list of lines. But there might be rows which has some spaces and \n",
    "    ## the value in the lat row is not a list but a string which has a square bracket\n",
    "    ## WE have to remove that.\n",
    "    remove_bracs=_conversation_list[1:-1]\n",
    "    remove_single_quotes=remove_bracs.replace(\"'\",\"\")\n",
    "    remove_unwanted_space=remove_single_quotes.replace(\" \",\"\")\n",
    "    conversations_id.append(remove_unwanted_space.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208'],\n",
       " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
       " ['L276', 'L277'],\n",
       " ['L280', 'L281'],\n",
       " ['L363', 'L364'],\n",
       " ['L365', 'L366']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_id[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now have cleaned and mapped the convos and lines from the text\n",
    "## Next job is to find the questions and the answers \n",
    "### This can be done by following examples:\n",
    "#### 1. Any conversation which start would be considered as question and second would be answer\n",
    "#### 2. So, here the first in the list of lines would be the quetion and second would be the answer.\n",
    "#### 3. And that answer will be passed as a question in the second row and for that question would be in the third row and so on..\n",
    "#### 3. Now we will seggregate the questions and answers and store the text from id2line dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[]\n",
    "answers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for line_list in conversations_id:\n",
    "    for line_no in range(len(line_list)-1):\n",
    "        #print('hello')\n",
    "        questions.append(id2line[line_list[line_no]])\n",
    "        answers.append(id2line[line_list[line_no+1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       " 'Not the hacking and gagging and spitting part.  Please.',\n",
       " \"You're asking me out.  That's so cute. What's your name again?\",\n",
       " \"No, no, it's my fault -- we didn't have a proper introduction ---\",\n",
       " 'Cameron.',\n",
       " \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\",\n",
       " 'Why?',\n",
       " 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.',\n",
       " 'Gosh, if only we could find Kat a boyfriend...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       " 'Not the hacking and gagging and spitting part.  Please.',\n",
       " \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\",\n",
       " 'Forget it.',\n",
       " 'Cameron.',\n",
       " \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\",\n",
       " 'Seems like she could get a date easy enough...',\n",
       " 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.',\n",
       " \"That's a shame.\",\n",
       " 'Let me see what I can do.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE have got the questions and answers.\n",
    "### Now time to clean some data\n",
    "#### We might have some text like i'm, we're etc.,\n",
    "#### WE will replace that with the actual text like i am, We are etc.,\n",
    "#### For that we will create a function and replace the words like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # We will utilize re library to replace\n",
    "    # WE will convert the text to lower case\n",
    "    text=text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\",text)\n",
    "    text= re.sub(r\"he's\",\"he is\",text)\n",
    "    text=re.sub(r\"she's\", \"she is\",text)\n",
    "    text=re.sub(r\"that's\",\"that is\",text)\n",
    "    text=re.sub(r\"what's\",\"what is\",text)\n",
    "    text=re.sub(r\"where's\",\"where is\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will\",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have\",text)\n",
    "    text=re.sub(r\"\\'d'\",\" would\",text)\n",
    "    text=re.sub(r\"\\'re\",\" are\",text)\n",
    "    text=re.sub(r\"won't\",\"will not\",text)\n",
    "    text=re.sub(r\"can't\",\"cannpt\",text)\n",
    "    text=re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,]\",\" \",text)\n",
    "    #print(text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will apply function to both question and ansewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_question=[]\n",
    "for q_list in questions:\n",
    "        clean_question.append(clean_text(q_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_answers=[]\n",
    "for a_list in answers:\n",
    "    clean_answers.append(clean_text(a_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can we make this quick   roxanne korrine and andrew barrett are having an incredibly horrendous public break  up on the quad   again ',\n",
       " \"well  i thought we'd start with pronunciation  if that is okay with you \",\n",
       " 'not the hacking and gagging and spitting part   please ',\n",
       " 'you are asking me out   that is so cute  what is your name again ',\n",
       " \"no  no  it's my fault    we didn't have a proper introduction    \",\n",
       " 'cameron ',\n",
       " 'the thing is  cameron    i am at the mercy of a particularly hideous breed of loser   my sister   i cannpt date until she does ',\n",
       " 'why ',\n",
       " 'unsolved mystery   she used to be really popular when she started high school  then it was just like she got sick of it or something ',\n",
       " 'gosh  if only we could find kat a boyfriend   ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_question[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"well  i thought we'd start with pronunciation  if that is okay with you \",\n",
       " 'not the hacking and gagging and spitting part   please ',\n",
       " \"okay    then how 'bout we try out some french cuisine   saturday   night \",\n",
       " 'forget it ',\n",
       " 'cameron ',\n",
       " 'the thing is  cameron    i am at the mercy of a particularly hideous breed of loser   my sister   i cannpt date until she does ',\n",
       " 'seems like she could get a date easy enough   ',\n",
       " 'unsolved mystery   she used to be really popular when she started high school  then it was just like she got sick of it or something ',\n",
       " 'that is a shame ',\n",
       " 'let me see what i can do ',\n",
       " 'right   see   you are ready for the quiz ',\n",
       " \"i don't want to know how to say that though   i want to know useful things  like where the good stores are   how much does champagne cost   stuff like chat   i have never in my life had to point out my head to someone \",\n",
       " \"that is because it's such a nice one \",\n",
       " 'forget french ',\n",
       " \"well  there's someone i think might be   \",\n",
       " 'where ',\n",
       " \"i counted on you to help my cause  you and that thug are obviously failing  aren't we ever going on our date \",\n",
       " 'you are sweet ',\n",
       " \"eber's deep conditioner every two days  and i never  ever use a blowdryer without the diffuser attachment \",\n",
       " 'i really  really  really wanna go  but i cannpt   not unless my sister goes ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_answers[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have cleaned the data of questions and answers.\n",
    "#### Now we have to create a dictionary which maps each word to its number of occurences.\n",
    "#### It will map like each word to how many times it has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets start with questions\n",
    "for ques in clean_question:\n",
    "    # Now go through all the words in each question\n",
    "    for word in ques.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now with answers\n",
    "for ans in clean_answers:\n",
    "    for word in ans.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we have the number of occurences\n",
    "## now lets dice into two important concepts\n",
    "### Tokenization and filtering the non-frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in this we will have twp dicts which map unique words from questions to one integers and another dict will map the answer unique words to another integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will go through non-frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "queswords2int={}\n",
    "answords2int={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop the wordcount and ad them in question dict\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if count > threshold:\n",
    "        # We will assingn that word to unique number\n",
    "        queswords2int[word] = word_number\n",
    "        word_number += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop the wordcount and add it in answerdict\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if count > threshold:\n",
    "        answords2int[word]=word_number\n",
    "        word_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answords2int['can']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will Add unique tokens to the dicts\n",
    "#### This tokens are used in encoding and decoding in seq2seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=['<PAD>', '<EOS>','<OUT>','<SOS>']\n",
    "## Lets append these values to the word count\n",
    "for token in tokens:\n",
    "    queswords2int[token]=len(queswords2int)+1\n",
    "    answords2int[token]=len(answords2int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8592"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queswords2int['<EOS>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have questions words dict with words as keys and count as values.\n",
    "#### for answers words we will swap those like count wouldbe the key and word would be the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "answords2word={c:w for w,c in answords2int.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concept'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answords2word[3454]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to add the EOS string to every answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_answers)):\n",
    "    clean_answers[i]= clean_answers[i] + ' <EOS>'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yeah  well  don't let it get out <EOS>\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_answers[345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will translate all the questions into integers\n",
    "### WE will loop all the words from clean question and map with words2int. if any word form question doesnot found in quesiton then we will replace it with out index number, otherwise normal index number of what that word have in the question2int dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions2int=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ques in clean_question:\n",
    "    ints=[]\n",
    "    for word in ques.split():\n",
    "        if word not in queswords2int:\n",
    "            ints.append(queswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(queswords2int[word])\n",
    "    questions2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  8593,\n",
       "  8593,\n",
       "  5,\n",
       "  6,\n",
       "  8593,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8593,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  8593,\n",
       "  16],\n",
       " [17, 18, 19, 20, 21, 22, 8593, 23, 24, 25, 26, 22, 27],\n",
       " [28, 15, 8593, 5, 8593, 5, 8593, 29, 30],\n",
       " [27, 7, 31, 32, 33, 24, 25, 34, 35, 36, 25, 37, 38, 16],\n",
       " [39, 39, 40, 41, 42, 1, 43, 44, 45, 46, 8593]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions2int[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WE will conver the same for answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2int=[]\n",
    "for ans in clean_answers:\n",
    "    ints=[]\n",
    "    for word in ans.split():\n",
    "        if word not in answords2int:\n",
    "            ints.append(answords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answords2int[word])\n",
    "    answer2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answords2int['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quick'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answords2word[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 18, 19, 20, 21, 22, 8593, 23, 24, 25, 26, 22, 27, 8592],\n",
       " [28, 15, 8593, 5, 8593, 5, 8593, 29, 30, 8592],\n",
       " [26, 73, 97, 1558, 1, 888, 33, 502, 402, 8593, 216, 247, 8592],\n",
       " [250, 74, 8592],\n",
       " [47, 8592]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer2int[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we will sort questions and answers \n",
    "### This we will do because when learning when we preset large sentence then the model could not able lo learn\n",
    "### Here we will restrict the question with 25 words and not more than that (This is variable where we can change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_questions=[]\n",
    "sorted_answers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length in range(1,26):\n",
    "    for index,words in enumerate(questions2int):\n",
    "        if len(words) == length:\n",
    "            sorted_questions.append(questions2int[index])\n",
    "            \n",
    "            sorted_answers.append(answer2int[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 18, 19, 20, 21, 22, 8593, 23, 24, 25, 26, 22, 27]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions2int[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 48,\n",
       " 25,\n",
       " 47,\n",
       " 18,\n",
       " 49,\n",
       " 50,\n",
       " 15,\n",
       " 51,\n",
       " 52,\n",
       " 45,\n",
       " 53,\n",
       " 8593,\n",
       " 54,\n",
       " 52,\n",
       " 55,\n",
       " 41,\n",
       " 56,\n",
       " 18,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 8592]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
